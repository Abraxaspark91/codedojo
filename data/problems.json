[
  {
    "pid": "python_basic_string_quotes",
    "title": "Python 문자열 표기법",
    "body": "users 데이터프레임에서 이름(name)이 'Alice'인 사람을 찾고 싶습니다. Python 코드 내에서 문자열 값을 표현할 때 사용할 수 있는 따옴표의 종류를 생각하며 filter 함수를 완성해보세요.",
    "schema": "users(name STRING, age INT)",
    "sample_rows": [
      "Alice | 25",
      "Bob | 30"
    ],
    "difficulty": "Lv0 기초",
    "kind": "Python",
    "hint": "Python에서는 작은따옴표(')와 큰따옴표(\") 중 무엇을 써도 상관없습니다. 시작과 끝만 일치시켜주세요.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_basic_string_literal",
    "title": "SQL 문자열 값 표기 규칙",
    "body": "SQL을 사용하여 name이 'Alice'인 유저를 조회하세요. SQL 문법에서 데이터 값(리터럴)을 감쌀 때 반드시 사용해야 하는 따옴표가 무엇인지 생각해보세요.",
    "schema": "users(name TEXT, age INT)",
    "sample_rows": [
      "Alice | 25",
      "Bob | 30"
    ],
    "difficulty": "Lv0 기초",
    "kind": "SQL",
    "hint": "SQL에서 문자열 값은 반드시 **작은따옴표(')**를 사용해야 합니다. 큰따옴표(\")는 컬럼명 등을 감쌀 때 쓰입니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_import_functions",
    "title": "PySpark 함수 모듈 불러오기",
    "body": "PySpark의 다양한 함수(col, lit, sum 등)를 사용하기 위해 `pyspark.sql.functions` 모듈을 import 하려고 합니다. 코드를 간결하게 쓰기 위해 통상적으로 사용하는 별칭(Alias)을 사용하여 import 문을 작성하세요.",
    "schema": "N/A (코드 설정 문제)",
    "sample_rows": [],
    "difficulty": "Lv0 기초",
    "kind": "Python.Pyspark",
    "hint": "`import ... as ...` 구문을 사용합니다. 보통 `F`라는 약어를 많이 사용합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_filter_null",
    "title": "PySpark 결측치(NULL) 필터링",
    "body": "users 데이터프레임에서 `email` 컬럼이 비어있는(NULL) 사용자만 조회하려고 합니다. Python의 `None`과 비교 연산자(`==`)를 사용하는 것은 올바르지 않습니다. PySpark 전용 메서드를 사용하세요.",
    "schema": "users(name STRING, email STRING)",
    "sample_rows": [
      "Alice | alice@test.com",
      "Bob | NULL",
      "Charlie | charlie@test.com"
    ],
    "difficulty": "Lv1 입문",
    "kind": "Python.Pyspark",
    "hint": "컬럼 객체 뒤에 `.isNull()` 메서드를 붙여서 확인해야 합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_filter_is_null",
    "title": "SQL 결측치(NULL) 조회 조건",
    "body": "SQL에서 email 정보가 없는(NULL) 사용자를 조회하세요. 일반적인 등호(`=`) 연산자로는 NULL 값을 찾아낼 수 없습니다. 올바른 SQL 조건식을 사용하세요.",
    "schema": "users(name TEXT, email TEXT)",
    "sample_rows": [
      "Alice | alice@test.com",
      "Bob | NULL"
    ],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "`컬럼명 IS NULL` 구문을 사용해야 합니다. (`= NULL`은 동작하지 않습니다.)",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_f_string_basic",
    "title": "변수를 활용한 문자열 조건 생성",
    "body": "외부 변수 `target_age = 30`이 주어졌을 때, 이를 활용하여 \"age >= 30\" 형태의 필터 조건 문자열을 만드세요. Python의 문자열 포맷팅 기능 중 하나를 사용하여 변수 값을 문자열 안에 삽입해야 합니다.",
    "schema": "users(name STRING, age INT)",
    "sample_rows": [
      "Alice | 25",
      "Bob | 35"
    ],
    "difficulty": "Lv0 기초",
    "kind": "Python.Pyspark",
    "hint": "따옴표 앞에 `f`를 붙이고, 변수를 중괄호 `{}` 안에 넣는 **f-string** 문법을 사용해보세요.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_basic_in_operator",
    "title": "다중 값 일치 검색",
    "body": "products 테이블에서 category가 'Fruit'이거나 'Vegetable'인 상품을 조회하세요. `OR` 연산자를 반복해서 사용하는 대신, 목록 중 하나와 일치하는지 확인하는 연산자를 사용하세요.",
    "schema": "products(name TEXT, category TEXT)",
    "sample_rows": [
      "Apple | Fruit",
      "Beef | Meat",
      "Carrot | Vegetable"
    ],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "`컬럼명 IN ('값1', '값2')` 형태의 문법을 사용하세요.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_col_object",
    "title": "PySpark 컬럼 연산 방식",
    "body": "`age` 컬럼의 값에 1을 더한 결과를 `age_plus_1`이라는 새로운 컬럼으로 만드세요. 문자열 \"age\"에 숫자를 더할 수 없으므로, 이를 컬럼 객체로 변환한 뒤 연산해야 합니다.",
    "schema": "users(name STRING, age INT)",
    "sample_rows": [
      "Alice | 20"
    ],
    "difficulty": "Lv1 입문",
    "kind": "Python.Pyspark",
    "hint": "`F.col(\"컬럼명\")` 함수를 사용하여 문자열을 컬럼 객체로 감싸주세요.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_alias_column",
    "title": "조회 결과 컬럼명 변경",
    "body": "price 컬럼에 0.9를 곱한 값을 조회하되, 결과 컬럼의 이름을 `discounted_price`로 지정하여 출력하세요.",
    "schema": "products(name TEXT, price DECIMAL)",
    "sample_rows": [
      "Mouse | 10000"
    ],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "계산식 뒤에 `AS 새로운이름`을 붙여줍니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_boolean_operators",
    "title": "PySpark 다중 조건 결합",
    "body": "age가 20 이상이고(AND), 30 미만인 사람을 필터링하세요. Python의 기본 키워드(`and`, `or`) 대신 PySpark 및 Pandas에서 사용하는 전용 비트 연산자를 사용해야 하며, 연산 순서에 주의해야 합니다.",
    "schema": "users(name STRING, age INT)",
    "sample_rows": [
      "Alice | 25",
      "Bob | 35"
    ],
    "difficulty": "Lv1 입문",
    "kind": "Python.Pyspark",
    "hint": "각 조건을 괄호 `()`로 감싸고, `&` (AND) 또는 `|` (OR) 연산자를 사용하세요.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_operator_not_equal",
    "title": "SQL: 특정 조건 제외하기",
    "body": "customers 테이블에서 status가 'inactive'가 **아닌** 고객들만 조회하고 싶습니다. '같다'는 `=`인데, '다르다(Not Equal)'는 어떤 기호를 써야 할까요?",
    "schema": "customers(id INT, status TEXT)",
    "sample_rows": [
      "1 | active",
      "2 | inactive",
      "3 | pending"
    ],
    "difficulty": "Lv0 기초",
    "kind": "SQL",
    "hint": "표준 SQL에서는 `<>`를 많이 쓰지만, `!=`도 대부분 지원합니다. 둘 중 하나를 사용해보세요.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_operator_not_equal",
    "title": "PySpark: 특정 조건 제외하기",
    "body": "users 데이터프레임에서 age가 20이 **아닌** 사람만 남기고 싶습니다. Python의 비교 연산자를 사용하여 필터링하세요.",
    "schema": "users(name STRING, age INT)",
    "sample_rows": [
      "Alice | 20",
      "Bob | 25"
    ],
    "difficulty": "Lv0 기초",
    "kind": "Python.Pyspark",
    "hint": "같다는 `==`이고, 다르다는 `!=` 입니다. `F.col('age') != 20` 형태로 작성합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_rename_column",
    "title": "PySpark: 컬럼 이름 변경",
    "body": "데이터프레임의 `user_name`이라는 컬럼 이름이 너무 길어서 `name`으로 단순하게 바꾸고 싶습니다. 컬럼의 **이름만** 변경하는 전용 메서드를 사용하세요.",
    "schema": "users(user_name STRING, age INT)",
    "sample_rows": [
      "Alice | 20"
    ],
    "difficulty": "Lv1 입문",
    "kind": "Python.Pyspark",
    "hint": "`df.withColumnRenamed('기존이름', '새이름')` 메서드를 사용합니다. `alias`는 select 할 때 쓰고, 이 메서드는 DF 자체를 변환할 때 씁니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_count_null_handling",
    "title": "SQL: 데이터 개수 세기와 NULL",
    "body": "orders 테이블의 전체 행 개수가 아니라, `customer_id`가 **비어있지 않은(NULL이 아닌)** 행의 개수만 세고 싶습니다. 괄호 안에 무엇을 넣어야 할까요?",
    "schema": "orders(id INT, customer_id INT)",
    "sample_rows": [
      "1 | 101",
      "2 | NULL",
      "3 | 102"
    ],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "`COUNT(*)`는 NULL 포함 전체를 세고, `COUNT(컬럼명)`은 해당 컬럼의 NULL을 제외하고 셉니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_drop_duplicates_simple",
    "title": "PySpark: 중복 데이터 제거",
    "body": "로그 데이터인 `logs` 데이터프레임에서 완전히 동일한 중복 행들을 제거하고 유니크한 행만 남기려고 합니다. 가장 직관적인 메서드를 사용하세요.",
    "schema": "logs(time STRING, user STRING)",
    "sample_rows": [
      "10:00 | Alice",
      "10:00 | Alice",
      "10:01 | Bob"
    ],
    "difficulty": "Lv1 입문",
    "kind": "Python.Pyspark",
    "hint": "`df.dropDuplicates()` 또는 `df.distinct()`를 사용합니다. 실무에서는 특정 컬럼 기준 중복 제거가 가능한 `dropDuplicates()`를 더 자주 씁니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_between_operator",
    "title": "SQL: 범위 검색 단순화",
    "body": "products 테이블에서 가격(price)이 1000 이상이고 2000 이하인 상품을 찾고 싶습니다. `>=`와 `<=`를 `AND`로 연결해도 되지만, 더 읽기 쉬운 전용 연산자가 있습니다.",
    "schema": "products(name TEXT, price INT)",
    "sample_rows": [
      "A | 500",
      "B | 1500",
      "C | 2500"
    ],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "`price BETWEEN 1000 AND 2000` 구문을 사용하세요. (시작과 끝 값을 포함합니다)",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_sort_descending",
    "title": "PySpark: 내림차순 정렬",
    "body": "scores 데이터프레임을 점수(score)가 높은 순서(내림차순)로 정렬하고 싶습니다. 단순히 `orderBy`만 쓰면 오름차순이 됩니다. 내림차순을 위해 필요한 함수는 무엇일까요?",
    "schema": "scores(name STRING, score INT)",
    "sample_rows": [
      "Alice | 50",
      "Bob | 100"
    ],
    "difficulty": "Lv1 입문",
    "kind": "Python.Pyspark",
    "hint": "`F.col('score').desc()` 함수를 사용해야 합니다. (`F.desc('score')`도 가능)",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_like_suffix",
    "title": "SQL: 끝나는 문자열 찾기",
    "body": "users 테이블에서 이메일이 '@gmail.com'으로 **끝나는** 모든 사용자를 조회하세요. 문자열 패턴 매칭 연산자를 사용해야 합니다.",
    "schema": "users(name TEXT, email TEXT)",
    "sample_rows": [
      "A | a@naver.com",
      "B | b@gmail.com"
    ],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "`email LIKE '%@gmail.com'`을 사용하세요. `%`는 '0개 이상의 아무 문자'를 뜻합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_startswith",
    "title": "PySpark: 시작하는 문자열 찾기",
    "body": "products 데이터프레임에서 상품명(name)이 'New'로 **시작하는** 상품만 필터링하세요. SQL의 LIKE보다 더 직관적인 Python 스타일의 문자열 메서드를 사용할 수 있습니다.",
    "schema": "products(name STRING, price INT)",
    "sample_rows": [
      "New Laptop | 100",
      "Old Mouse | 10"
    ],
    "difficulty": "Lv1 입문",
    "kind": "Python.Pyspark",
    "hint": "`F.col('name').startswith('New')` 메서드를 사용하세요. 코드가 훨씬 읽기 좋아집니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_select_math",
    "title": "SQL: 계산 결과 조회",
    "body": "employees 테이블에서 연봉(salary)을 12로 나눈 'monthly_salary'를 조회하고 싶습니다. SELECT 문 안에서 바로 나눗셈 연산을 수행하세요.",
    "schema": "employees(name TEXT, salary INT)",
    "sample_rows": [
      "Alice | 12000"
    ],
    "difficulty": "Lv0 기초",
    "kind": "SQL",
    "hint": "`salary / 12 AS monthly_salary` 처럼 작성하면 됩니다. SQL은 SELECT 절에서 사칙연산이 가능합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_select_subset",
    "title": "PySpark: 원하는 컬럼만 골라내기",
    "body": "데이터프레임에 컬럼이 100개쯤 되는데, 그 중에서 `id`와 `email` 두 개의 컬럼만 딱 뽑아서 새로운 데이터프레임을 만들고 싶습니다.",
    "schema": "users(id INT, email STRING, address STRING, phone STRING ...)",
    "sample_rows": [
      "1 | a@test.com | Seoul | 010..."
    ],
    "difficulty": "Lv0 기초",
    "kind": "Python.Pyspark",
    "hint": "`df.select('id', 'email')`을 사용하세요. 분석의 첫 단계는 필요한 데이터만 남기는 것입니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_cast_string_to_int",
    "title": "PySpark: 문자열을 숫자로 변환",
    "body": "`age` 컬럼이 숫자가 아닌 문자열(\"25\")로 저장되어 있어서 산술 연산이 안 됩니다. 이를 숫자(Integer) 타입으로 변환하세요.",
    "schema": "users(name STRING, age STRING)",
    "sample_rows": [
      "Alice | \"25\""
    ],
    "difficulty": "Lv1 입문",
    "kind": "Python.Pyspark",
    "hint": "`F.col('age').cast('int')` 또는 `.cast('integer')`를 사용합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_coalesce_basic",
    "title": "SQL: 빈 값(NULL)을 다른 값으로 대체하기",
    "body": "customers 테이블에서 전화번호(phone)를 조회하고 싶습니다. 그런데 전화번호가 NULL인 경우에는 '미입력'이라고 출력하고 싶습니다. IF문을 쓰지 않고도 이를 처리하는 아주 유용한 표준 함수가 있습니다.",
    "schema": "customers(name TEXT, phone TEXT)",
    "sample_rows": [
      "Alice | 010-1234-5678",
      "Bob | NULL"
    ],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "`COALESCE(컬럼명, '대체값')` 함수를 사용하세요. NULL이 아니면 원래 값을, NULL이면 뒤의 값을 반환합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_when_otherwise",
    "title": "PySpark: 조건에 따라 다른 값 넣기 (if-else)",
    "body": "products 데이터프레임에서 `price`가 10000 이상이면 'High', 그렇지 않으면 'Low'라는 값을 가진 `price_level` 컬럼을 새로 만들고 싶습니다. Python의 `if-else` 문법 대신 PySpark 전용 함수를 사용해야 합니다.",
    "schema": "products(name STRING, price INT)",
    "sample_rows": [
      "Mouse | 5000",
      "Keyboard | 15000"
    ],
    "difficulty": "Lv1 입문",
    "kind": "Python.Pyspark",
    "hint": "`F.when(조건, 값).otherwise(값)` 형태를 사용합니다. 아주 자주 쓰이는 패턴입니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_literal_column",
    "title": "PySpark: 모든 행에 똑같은 값(상수) 넣기",
    "body": "users 데이터프레임에 `is_active`라는 컬럼을 추가하고, 모든 유저에게 `True` 값을 주고 싶습니다. `withColumn('is_active', True)`라고 쓰면 에러가 납니다. 값을 컬럼 객체로 만들어주는 함수가 필요합니다.",
    "schema": "users(name STRING)",
    "sample_rows": [
      "Alice",
      "Bob"
    ],
    "difficulty": "Lv1 입문",
    "kind": "Python.Pyspark",
    "hint": "단순한 값(숫자, 문자, 불린)을 컬럼으로 넣을 때는 반드시 `F.lit(값)`으로 감싸야 합니다. (Literal의 줄임말)",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_logic_precedence",
    "title": "SQL: AND와 OR가 섞여 있을 때",
    "body": "products 테이블에서 (카테고리가 'Electronics'이거나 'Computer')이고, 동시에 (가격이 10000 이상)인 상품을 조회하세요. 괄호 없이 그냥 나열하면 의도와 다른 결과가 나옵니다.",
    "schema": "products(name TEXT, category TEXT, price INT)",
    "sample_rows": [
      "Mouse | Electronics | 5000",
      "Monitor | Computer | 20000"
    ],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "AND는 OR보다 우선순위가 높습니다. 따라서 OR 조건을 먼저 묶어주려면 반드시 **괄호 `()`**를 사용해야 합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_print_schema",
    "title": "PySpark: 데이터 구조(타입) 확인하기",
    "body": "데이터를 로드했는데 `age`가 숫자인지 문자인지, `reg_date`가 날짜인지 문자인지 헷갈립니다. 데이터프레임의 컬럼 이름과 데이터 타입을 트리 형태로 예쁘게 출력해서 확인하는 메서드는 무엇일까요?",
    "schema": "N/A (데이터 확인 문제)",
    "sample_rows": [],
    "difficulty": "Lv0 기초",
    "kind": "Python.Pyspark",
    "hint": "`df.printSchema()`를 실행하면 스키마 정보를 눈으로 확인할 수 있습니다. 디버깅할 때 필수입니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_min_max_basic",
    "title": "SQL: 최솟값과 최댓값 구하기",
    "body": "employees 테이블에서 가장 높은 연봉(salary)과 가장 낮은 연봉을 알고 싶습니다. 두 개의 집계 함수를 사용하여 한 번에 조회하세요.",
    "schema": "employees(name TEXT, salary INT)",
    "sample_rows": [
      "Alice | 5000",
      "Bob | 9000"
    ],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "`MAX(salary)`, `MIN(salary)`를 사용합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_show_action",
    "title": "PySpark: 데이터 눈으로 확인하기",
    "body": "열심히 필터링하고 컬럼을 추가했습니다. 이제 결과 데이터의 상위 20줄을 화면에 출력해서 제대로 처리되었는지 확인하고 싶습니다. 가장 많이 쓰는 'Action' 메서드는 무엇일까요?",
    "schema": "result_df(name STRING, age INT)",
    "sample_rows": [],
    "difficulty": "Lv0 기초",
    "kind": "Python.Pyspark",
    "hint": "`df.show()`를 사용합니다. 괄호 안에 숫자를 넣어 `df.show(5)` 처럼 줄 수를 지정할 수도 있습니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_date_string_format",
    "title": "SQL: 날짜 형식의 문자열 검색",
    "body": "orders 테이블에서 `order_date`가 '2024-01-01' 이후인 주문을 조회하고 싶습니다. 날짜 컬럼과 문자열을 비교할 때, 날짜 포맷(형식)을 어떻게 맞춰야 할까요?",
    "schema": "orders(id INT, order_date DATE)",
    "sample_rows": [
      "1 | 2023-12-31",
      "2 | 2024-01-02"
    ],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "SQL 표준 날짜 포맷은 **'YYYY-MM-DD'**입니다. `order_date > '2024-01-01'` 처럼 작은따옴표로 감싸서 비교하면 자동으로 날짜로 인식합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_fill_null",
    "title": "PySpark: 결측치(NULL) 일괄 채우기",
    "body": "users 데이터프레임에 `age`가 비어있는(NULL) 행들이 있습니다. 비어있는 나이를 모두 0으로 채워넣고 싶습니다. `fillna` (또는 `na.fill`) 함수를 사용해보세요.",
    "schema": "users(name STRING, age INT)",
    "sample_rows": [
      "Alice | NULL",
      "Bob | 25"
    ],
    "difficulty": "Lv1 입문",
    "kind": "Python.Pyspark",
    "hint": "`df.fillna(0, subset=['age'])` 형태로 사용합니다. 특정 컬럼을 지정하지 않으면 호환되는 모든 컬럼을 채워버리니 주의하세요.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_distinct_count",
    "title": "SQL: 중복을 제외한 수 세기",
    "body": "access_logs 테이블에는 유저가 접속할 때마다 로그가 쌓입니다. 총 접속 횟수가 아니라, 접속한 **유저가 몇 명인지(고유 방문자 수)** 알고 싶다면 `COUNT` 안에 무엇을 추가해야 할까요?",
    "schema": "access_logs(log_id INT, user_id INT)",
    "sample_rows": [
      "1 | 100",
      "2 | 100",
      "3 | 200"
    ],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "`COUNT(DISTINCT user_id)`를 사용합니다. 중복을 제거한 뒤 개수를 셉니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_chaining",
    "title": "PySpark: 메서드 체이닝 (점 찍어 연결하기)",
    "body": "PySpark의 큰 장점은 코드를 한 줄씩 끊어 쓰지 않고 연결할 수 있다는 점입니다. (1) `age`가 20 이상인 사람을 필터링하고 (2) `name` 컬럼만 선택하는 과정을 **점(.)**으로 연결해서 한 번에 작성해보세요.",
    "schema": "users(name STRING, age INT, city STRING)",
    "sample_rows": [
      "Alice | 25 | Seoul",
      "Bob | 15 | Busan"
    ],
    "difficulty": "Lv1 입문",
    "kind": "Python.Pyspark",
    "hint": "`df.filter(조건).select(컬럼)` 처럼 메서드 뒤에 바로 점을 찍어 다음 메서드를 연결하는 방식을 '체이닝'이라고 합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_concat_strings",
    "title": "SQL: 문자열 합치기",
    "body": "first_name이 'Gildong', last_name이 'Hong'일 때, 이를 합쳐서 'Gildong Hong' (중간에 공백 포함)이라는 `full_name`을 만들고 싶습니다. 문자열 연결 연산자나 함수를 사용하세요.",
    "schema": "users(first_name TEXT, last_name TEXT)",
    "sample_rows": [
      "Gildong | Hong"
    ],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "데이터베이스마다 다르지만 표준적으로 `CONCAT(first_name, ' ', last_name)`을 쓰거나, `||` 기호를 사용합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_select_distinct_category",
    "title": "중복 제거와 카디널리티 확인",
    "body": "products 테이블에서 현재 판매 중인 상품들의 카테고리(category) 목록을 조회하세요. 동일한 카테고리가 여러 번 출력되지 않아야 하며, 결과는 알파벳 순으로 정렬하세요. 실무에서는 컬럼의 고유 값 개수(Cardinality)를 파악할 때 자주 사용됩니다.",
    "schema": "products(product_id INT, category TEXT, price DECIMAL)",
    "sample_rows": [
      "1 | Electronics | 120000",
      "2 | Electronics | 35000",
      "3 | Books | 15000",
      "4 | Beauty | 25000"
    ],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "`SELECT DISTINCT category`를 사용하여 중복을 제거한 후 정렬하세요.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_filter_literal",
    "title": "상수 컬럼 추가와 리터럴 처리",
    "body": "users 데이터프레임에 'country'라는 새로운 컬럼을 추가하고, 모든 행에 'Korea'라는 값을 입력하세요. PySpark에서는 문자열 값을 직접 컬럼으로 다룰 때 함수 사용이 필요합니다.",
    "schema": "users(user_id INT, name STRING)",
    "sample_rows": [
      "1 | Alice",
      "2 | Bob"
    ],
    "difficulty": "Lv1 입문",
    "kind": "Python.Pyspark",
    "hint": "단순 문자열을 할당하면 에러가 납니다. `df.withColumn('country', F.lit('Korea'))`를 사용하세요.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_where_null_check",
    "title": "NULL 값과 빈 문자열의 차이",
    "body": "customers 테이블에서 이메일(email) 정보가 없는 고객을 조회하세요. 데이터베이스에 따라 '정보 없음'이 NULL로 저장되기도 하고, 빈 문자열('')로 저장되기도 하므로 두 경우를 모두 고려해야 합니다.",
    "schema": "customers(id INT, name TEXT, email TEXT)",
    "sample_rows": [
      "1 | Alice | alice@example.com",
      "2 | Bob | NULL",
      "3 | Charlie | ",
      "4 | David | david@example.com"
    ],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "`WHERE email IS NULL OR email = ''` 조건을 사용하세요. `email = NULL`은 동작하지 않습니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_cast_type",
    "title": "데이터 타입 변환과 스키마 불일치",
    "body": "sales 데이터의 price 컬럼이 실수로 문자열(STRING) 타입으로 적재되었습니다. 이를 정수형(INTEGER)으로 변환한 뒤, 가격이 10000원 이상인 데이터만 필터링하세요.",
    "schema": "sales(product_id INT, price STRING)",
    "sample_rows": [
      "101 | '5000'",
      "102 | '15000'",
      "103 | '900'"
    ],
    "difficulty": "Lv1 입문",
    "kind": "Python.Pyspark",
    "hint": "`df.withColumn('price', F.col('price').cast('int'))`로 타입을 변경한 후 필터링을 수행하세요.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_order_limit",
    "title": "상위 N개 추출: 정렬과 제한",
    "body": "orders 테이블에서 가장 최근에 주문된 5개의 주문 기록을 조회하세요. 전체 데이터를 가져온 후 애플리케이션에서 자르는 것보다, DB단에서 필요한 데이터만 가져오는 것이 네트워크 비용 절감에 유리합니다.",
    "schema": "orders(order_id INT, amount DECIMAL, order_date TIMESTAMP)",
    "sample_rows": [
      "1 | 50000 | 2024-03-01 10:00:00",
      "2 | 10000 | 2024-03-01 10:05:00",
      "3 | 30000 | 2024-03-01 09:00:00"
    ],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "`ORDER BY order_date DESC LIMIT 5` 구문을 사용하세요.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_select_alias",
    "title": "컬럼 선택과 이름 변경(Alias)",
    "body": "복잡한 컬럼명(product_manufacturing_cost)을 분석하기 쉽게 `cost`로 이름을 변경하여 선택하고, `product_id`와 함께 출력하세요. 긴 컬럼명은 코드를 읽기 어렵게 만듭니다.",
    "schema": "products(product_id INT, product_manufacturing_cost DOUBLE)",
    "sample_rows": [
      "1 | 15.50",
      "2 | 20.00"
    ],
    "difficulty": "Lv1 입문",
    "kind": "Python.Pyspark",
    "hint": "`df.select(F.col('product_id'), F.col('product_manufacturing_cost').alias('cost'))`를 사용하세요.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_like_wildcard",
    "title": "특정 패턴 검색: 인덱스와 Like",
    "body": "users 테이블에서 이름이 'J'로 시작하는 모든 사용자를 조회하세요. 문자열 패턴 검색 시 와일드카드(%)의 위치에 따라 인덱스 활용 여부가 달라질 수 있습니다.",
    "schema": "users(user_id INT, name TEXT)",
    "sample_rows": [
      "1 | James",
      "2 | Alice",
      "3 | John",
      "4 | Robert"
    ],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "`WHERE name LIKE 'J%'`를 사용하세요. `%J%`와 달리 접두사 검색은 인덱스를 탈 가능성이 높습니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_drop_columns",
    "title": "불필요한 컬럼 삭제: 메모리 최적화",
    "body": "분석에 필요 없는 민감 정보인 `password`와 `ssn` 컬럼을 데이터프레임에서 제거하세요. 불필요한 데이터를 계속 들고 다니는 것은 메모리 낭비의 주원인입니다.",
    "schema": "users(user_id INT, name STRING, password STRING, ssn STRING)",
    "sample_rows": [
      "1 | Alice | 1234 | 111-222",
      "2 | Bob | abcd | 333-444"
    ],
    "difficulty": "Lv1 입문",
    "kind": "Python.Pyspark",
    "hint": "`df.drop('password', 'ssn')`과 같이 여러 컬럼을 한 번에 삭제할 수 있습니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_basic_math",
    "title": "파생 변수 생성: 산술 연산",
    "body": "products 테이블에서 가격(price)에 10% 부가세를 더한 `final_price`를 계산하여 조회하세요. 기존 컬럼을 조합하여 새로운 지표를 만드는 것은 데이터 분석의 기초입니다.",
    "schema": "products(product_id INT, price DECIMAL)",
    "sample_rows": [
      "1 | 10000",
      "2 | 20000"
    ],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "`SELECT product_id, price, price * 1.1 AS final_price FROM products`와 같이 작성하세요.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_isin_filter",
    "title": "다중 값 필터링: OR 조건의 단순화",
    "body": "products 데이터에서 카테고리가 'Electronics', 'Books', 'Garden' 중 하나인 상품만 필터링하세요. OR 조건을 여러 번 쓰는 것보다 포함 여부를 확인하는 것이 가독성에 좋습니다.",
    "schema": "products(product_id INT, category STRING)",
    "sample_rows": [
      "1 | Electronics",
      "2 | Beauty",
      "3 | Books",
      "4 | Toys"
    ],
    "difficulty": "Lv1 입문",
    "kind": "Python.Pyspark",
    "hint": "`df.filter(F.col('category').isin(['Electronics', 'Books', 'Garden']))`을 사용하세요.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_boolean_logic",
    "title": "복합 논리 연산: AND와 괄호의 중요성",
    "body": "inventory 테이블에서 재고(stock)가 10개 미만이면서, 동시에 단종되지 않은(is_discontinued = 'N') 상품을 조회하세요. 긴급 발주가 필요한 목록입니다.",
    "schema": "inventory(product_id INT, stock INT, is_discontinued CHAR(1))",
    "sample_rows": [
      "1 | 5 | N",
      "2 | 0 | Y",
      "3 | 20 | N",
      "4 | 8 | Y"
    ],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "`WHERE stock < 10 AND is_discontinued = 'N'` 조건을 사용하세요.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_orderby_multiple",
    "title": "다중 정렬 기준: 우선순위 적용",
    "body": "employees 데이터를 부서(department)별로 오름차순 정렬하되, 같은 부서 내에서는 연봉(salary)이 높은 순서(내림차순)로 정렬하세요.",
    "schema": "employees(name STRING, department STRING, salary INT)",
    "sample_rows": [
      "Alice | Sales | 5000",
      "Bob | Sales | 6000",
      "Charlie | HR | 4000"
    ],
    "difficulty": "Lv1 입문",
    "kind": "Python.Pyspark",
    "hint": "`df.orderBy(F.col('department').asc(), F.col('salary').desc())`와 같이 정렬 기준을 순서대로 나열하세요.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_select_filter",
    "title": "신규 고객 조회와 인덱스 활용",
    "body": "customers 테이블에서 가입일(signup_date)이 2024-01-01 이후인 고객을 조회하세요. signup_date 컬럼에 인덱스가 걸려있다고 가정할 때, 함수 사용을 자제하고 원본 컬럼을 그대로 사용하여 조회 성능을 최적화해야 합니다.",
    "schema": "customers(id INT, name TEXT, signup_date DATE)",
    "sample_rows": [
      "1 | Alice | 2024-02-10",
      "2 | Bob | 2023-12-30",
      "3 | Casey | 2024-03-01",
      "4 | David | NULL",
      "5 | Eve | 2024-01-01"
    ],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "컬럼을 가공(예: YEAR(signup_date))하면 인덱스를 타지 않을 수 있습니다. `signup_date >= '2024-01-01'`과 같이 원본 컬럼을 그대로 비교하세요.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_aggregation_monthly",
    "title": "월별 매출 보고서: 날짜 절삭과 포맷팅",
    "body": "sales 테이블에서 월별 총 매출액을 계산하세요. 분석 툴(BI)에서 인식하기 쉽도록 문자열이 아닌 날짜 타입으로 월의 첫날(예: 2024-01-01)을 기준으로 그룹화하고, 출력 시에만 포맷을 변경하는 것이 좋습니다.",
    "schema": "sales(order_date DATE, amount DECIMAL)",
    "sample_rows": [
      "2024-01-05 | 120000",
      "2024-01-18 | 98000",
      "2024-02-02 | 150000",
      "NULL | 10000",
      "2024-02-28 | 5000"
    ],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "`DATE_TRUNC('month', order_date)`를 사용하여 월 단위로 절삭한 후 그룹화하세요.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_join_customer_orders",
    "title": "고객별 주문 합계: 1:N 조인과 데이터 뻥튀기 주의",
    "body": "customers와 orders 테이블을 INNER JOIN하여 고객별 총 주문 금액을 구하세요. 실무에서는 조인 키가 중복될 경우 결과 행이 의도치 않게 늘어나는(Fan-out) 현상을 주의해야 합니다.",
    "schema": "customers(cust_id INT, name TEXT)\norders(order_id INT, cust_id INT, amount DECIMAL)",
    "sample_rows": [
      "customers: 1 | Alice",
      "customers: 2 | Bob",
      "orders: 10 | 1 | 50000",
      "orders: 11 | NULL | 30000",
      "orders: 12 | 2 | 45000",
      "orders: 13 | 1 | 20000"
    ],
    "difficulty": "Lv3 중급",
    "kind": "SQL",
    "hint": "조인 조건은 `ON c.cust_id = o.cust_id`입니다. 집계 함수 `SUM(amount)`는 조인 결과 집합에 대해 수행됨을 유의하세요.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_window_rank",
    "title": "카테고리별 인기 상품: 동점자 처리 전략",
    "body": "products 테이블에서 카테고리별 가장 비싼 상품을 조회하세요. 비즈니스 요건상 가격이 동일하다면 공동 1등으로 모두 보여줘야 합니다. 이런 경우 적절한 윈도우 함수를 선택해야 합니다.",
    "schema": "products(id INT, category TEXT, price DECIMAL)",
    "sample_rows": [
      "1 | electronics | 120000",
      "2 | electronics | 120000",
      "3 | electronics | 90000",
      "4 | books | 18000",
      "5 | books | 15000"
    ],
    "difficulty": "Lv4 고급",
    "kind": "SQL",
    "hint": "`ROW_NUMBER()`는 강제로 순위를 매기지만, `RANK()`나 `DENSE_RANK()`는 동점을 처리합니다. 공동 1등을 모두 포함하려면 `RANK()`를 사용하세요.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_running_total",
    "title": "누적 매출 집계: 윈도우 함수의 정렬 비용",
    "body": "sales 테이블에서 월별 매출과 함께 '누적 매출'을 계산하세요. 윈도우 함수 사용 시 정렬(ORDER BY)은 비용이 많이 드는 작업이므로, 인덱스가 있다면 이를 활용하는 것이 좋으나 여기서는 쿼리로 해결합니다.",
    "schema": "sales(month TEXT, amount DECIMAL)",
    "sample_rows": [
      "2024-01 | 200000",
      "2024-03 | 180000",
      "2024-02 | 230000",
      "2024-04 | 150000"
    ],
    "difficulty": "Lv5 심화",
    "kind": "SQL",
    "hint": "`SUM(amount) OVER (ORDER BY month)` 구문을 사용하세요. 문자열 날짜 포맷이 'YYYY-MM'으로 통일되어 있다면 별도 캐스팅 없이 정렬 가능합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_basic_filter",
    "title": "활성 유저 필터링: Boolean 타입과 Predicate Pushdown",
    "body": "users DataFrame에서 활성 유저(active=True)이면서 마지막 로그인이 2024년 이후인 데이터를 필터링하세요. 파케이(Parquet) 등의 포맷을 사용할 때 필터 순서는 데이터 스캔량을 줄이는 데 영향을 줄 수 있습니다.",
    "schema": "users(id INT, active BOOLEAN, last_login TIMESTAMP)",
    "sample_rows": [
      "1 | true | 2024-02-03 10:00:00",
      "2 | false | NULL",
      "3 | true | 2023-12-10 15:30:00",
      "4 | true | 2024-01-05 09:20:00"
    ],
    "difficulty": "Lv1 입문",
    "kind": "Python.Pyspark",
    "hint": "`df.filter((F.col('active') == True) & (F.col('last_login') >= F.lit('2024-01-01')))` 형태로 작성하세요.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_join",
    "title": "주문 데이터 결합: 셔플링(Shuffling)과 성능",
    "body": "customers와 orders DataFrame을 INNER JOIN 하세요. 두 테이블 모두 크기가 클 경우, 조인 키를 기준으로 대규모 데이터 이동(Shuffle)이 발생하여 성능 저하의 원인이 됩니다.",
    "schema": "customers(cust_id INT, name STRING)\norders(order_id INT, cust_id INT, amount DOUBLE)",
    "sample_rows": [
      "Cust: 1 | Alice",
      "Cust: 2 | Bob",
      "Ord: 10 | 1 | 50000.0",
      "Ord: 11 | 3 | 30000.0",
      "Ord: 12 | 2 | 10000.0"
    ],
    "difficulty": "Lv2 초급",
    "kind": "Python.Pyspark",
    "hint": "`orders.join(customers, on='cust_id', how='inner')`를 사용합니다. 키 컬럼의 이름이 같다면 `on` 파라미터를 단일 문자열로 전달하는 것이 깔끔합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_window",
    "title": "센서 데이터 이동 평균: 윈도우 정의와 파티셔닝",
    "body": "events 데이터에서 시간 순으로 정렬하여 직전 2개 데이터와 현재 데이터의 평균(Moving Average)을 구하세요. 단일 파티션으로 윈도우를 몰아넣으면(OOM 위험), 병렬 처리가 불가능하므로 적절한 파티션 키가 필요할 수 있습니다.",
    "schema": "events(device_id INT, time TIMESTAMP, value DOUBLE)",
    "sample_rows": [
      "1 | 10:00 | 10.0",
      "1 | 10:05 | 14.0",
      "1 | 10:10 | 12.0",
      "2 | 10:00 | 20.0"
    ],
    "difficulty": "Lv3 중급",
    "kind": "Python.Pyspark",
    "hint": "`Window.partitionBy('device_id').orderBy('time').rowsBetween(-2, 0)`을 정의하여 디바이스별로 계산되도록 하세요.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_pivot",
    "title": "주간 상태 리포트: 피벗(Pivot)과 카디널리티",
    "body": "logs 데이터에서 각 주차(Week)별로 상태 코드(status)의 발생 횟수를 피벗하여 집계하세요. 피벗 대상 컬럼(status)의 고유 값(Cardinality)이 너무 많으면 컬럼 폭발이 일어날 수 있으니 주의해야 합니다.",
    "schema": "logs(timestamp TIMESTAMP, status STRING)",
    "sample_rows": [
      "2024-01-02 | success",
      "2024-01-03 | fail",
      "2024-01-08 | success",
      "2024-01-09 | pending"
    ],
    "difficulty": "Lv4 고급",
    "kind": "Python.Pyspark",
    "hint": "`df.groupBy(F.date_trunc('week', 'timestamp')).pivot('status').count()`를 사용하고, 결측치는 `.fillna(0)`으로 처리하세요.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_sessionize",
    "title": "세션 ID 생성: Lag 함수를 이용한 복합 로직",
    "body": "유저별로 페이지 방문 기록이 있습니다. 이전 방문과 30분 이상 차이가 나면 새로운 세션으로 간주하여 고유 세션 ID를 부여하세요. 이는 Clickstream 데이터 분석의 핵심 로직입니다.",
    "schema": "pageviews(user_id INT, ts TIMESTAMP)",
    "sample_rows": [
      "1 | 10:00",
      "1 | 10:10",
      "1 | 11:00 (New Session)",
      "1 | 11:05"
    ],
    "difficulty": "Lv5 심화",
    "kind": "Python.Pyspark",
    "hint": "1. `F.lag('ts')`로 이전 시간 확보 \n2. 시간 차이 > 30분이면 1, 아니면 0인 플래그 생성 \n3. 해당 플래그를 누적 합(`F.sum`)하여 세션 ID 생성.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_broadcast_join_large_small",
    "title": "브로드캐스트 조인 최적화: 셔플 제거",
    "body": "매우 큰 주문 테이블(df_large)과 작은 코드 테이블(df_small, 10MB 미만)을 조인할 때, 작은 테이블을 각 노드로 복사(Broadcast)하여 네트워크 비용(Shuffle)을 획기적으로 줄이세요.",
    "schema": "df_large(id INT, code_id INT, amount INT)\ndf_small(code_id INT, description STRING)",
    "sample_rows": [
      "Large: 1M rows...",
      "Small: 100 rows (1 | 'Discount', 2 | 'Regular')"
    ],
    "difficulty": "Lv3 중급",
    "kind": "Python.Pyspark",
    "hint": "`df_large.join(F.broadcast(df_small), 'code_id')` 구문을 사용하여 스파크가 맵 사이드 조인(Map-side Join)을 수행하도록 유도하세요.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_explode_array_to_rows",
    "title": "JSON 배열 처리: Explode와 데이터 정규화",
    "body": "한 유저가 구매한 상품들이 배열(Array) 형태로 저장되어 있습니다. 이를 분석하기 쉽게 상품당 한 행(Row)을 가지도록 펼쳐주세요(Normalize). 배열 크기가 클 경우 데이터 양이 급증할 수 있습니다.",
    "schema": "orders(user_id INT, items ARRAY<STRING>)",
    "sample_rows": [
      "1 | ['Apple', 'Banana']",
      "2 | ['Cherry']",
      "3 | []",
      "4 | NULL"
    ],
    "difficulty": "Lv2 초급",
    "kind": "Python.Pyspark",
    "hint": "`df.select('user_id', F.explode('items').alias('item'))`을 사용하세요. `explode_outer`를 쓰면 빈 배열도 보존할 수 있습니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_udf_string_length",
    "title": "사용자 정의 함수(UDF) 주의점: 직렬화 비용",
    "body": "name 컬럼의 길이를 구하세요. Python UDF는 JVM과 Python 프로세스 간 데이터 이동(직렬화/역직렬화) 비용이 크므로, 가능한 Spark 내장 함수를 사용하는 것이 성능에 유리합니다.",
    "schema": "users(name STRING)",
    "sample_rows": [
      "Alice",
      "Bob",
      "Christopher"
    ],
    "difficulty": "Lv2 초급",
    "kind": "Python.Pyspark",
    "hint": "단순 길이는 `F.length('name')` 내장 함수가 가장 빠릅니다. 굳이 UDF를 써야 한다면 `@F.udf(returnType=IntegerType())` 데코레이터를 사용하세요.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_repartition_coalesce",
    "title": "파티션 제어: Coalesce vs Repartition",
    "body": "작업 후 파티션 개수가 100개인데 파일 크기가 너무 작습니다(Small File Issue). 셔플링을 최소화하면서 파티션 개수를 1개로 줄여 단일 파일로 저장하고 싶습니다.",
    "schema": "df(id INT, data STRING)",
    "sample_rows": [
      "Partition 1: 10 rows",
      "Partition 2: 5 rows",
      "..."
    ],
    "difficulty": "Lv3 중급",
    "kind": "Python.Pyspark",
    "hint": "`df.repartition(1)`은 전체 셔플을 유발합니다. 단순히 파티션을 합치는 것이라면 `df.coalesce(1)`이 훨씬 효율적입니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_cache_usage",
    "title": "중간 결과 재사용: Cache와 Persist 전략",
    "body": "복잡한 전처리를 거친 DataFrame을 사용하여 두 가지 다른 분석(액션)을 수행합니다. 전처리 과정이 두 번 실행되지 않도록 메모리에 캐싱하세요. 메모리가 부족할 경우 디스크 스필(Spill)이 발생할 수 있습니다.",
    "schema": "heavy_df(id INT, computed_value DOUBLE)",
    "sample_rows": [
      "1 | 0.123 (computed costly)",
      "2 | 0.456 (computed costly)"
    ],
    "difficulty": "Lv2 초급",
    "kind": "Python.Pyspark",
    "hint": "`df.cache()` 호출 후 첫 번째 액션(`count()` 등)이 일어날 때 메모리에 적재됩니다. 작업이 끝나면 `df.unpersist()`로 해제하는 것이 좋습니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_null_cleaning_sales",
    "title": "더러운 데이터 정제: 유효성 검사",
    "body": "매출 금액이 음수이거나 NULL인 경우는 시스템 오류로 간주합니다. 유효한 매출(양수)과 2024년 데이터만 조회하세요. 현업 데이터는 항상 예상 범위를 벗어날 수 있음을 가정해야 합니다.",
    "schema": "sales(product_name TEXT, order_date DATE, amount DECIMAL)",
    "sample_rows": [
      "Laptop | 2024-01-05 | 150000",
      "Mouse | 2023-12-28 | NULL",
      "Keyboard | 2024-02-10 | -5000"
    ],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "`WHERE amount > 0` 조건은 암시적으로 NULL을 배제합니다. 날짜 필터는 `order_date >= '2024-01-01'`을 사용하세요.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_agg_approx_count",
    "title": "대용량 고유 유저 수: 근사 집계(HyperLogLog)",
    "body": "수십억 건의 로그에서 고유 방문자 수(Distinct Users)를 구해야 합니다. 정확한 `distinct count`는 메모리를 많이 사용하고 느립니다. 오차 허용 범위 내에서 빠르게 결과를 내는 근사 함수를 사용하세요.",
    "schema": "logs(user_id STRING, page_id STRING)",
    "sample_rows": [
      "uuid-1 | home",
      "uuid-2 | detail",
      "uuid-1 | cart"
    ],
    "difficulty": "Lv4 고급",
    "kind": "Python.Pyspark",
    "hint": "`F.countDistinct('user_id')` 대신 `F.approx_count_distinct('user_id', rsd=0.05)`를 사용하면 훨씬 빠른 속도로 근사치를 얻을 수 있습니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_cte_readability",
    "title": "복잡한 쿼리 구조화: CTE(Common Table Expression) 활용",
    "body": "카테고리별 매출 합계를 구하고, 그 중 평균 매출보다 높은 카테고리만 조회하세요. 서브쿼리를 중첩(Nested Subquery)하는 것보다 CTE를 사용하면 가독성과 유지보수성이 좋아집니다.",
    "schema": "sales(category TEXT, amount DECIMAL)",
    "sample_rows": [
      "A | 100",
      "B | 200",
      "A | 150",
      "C | 50"
    ],
    "difficulty": "Lv3 중급",
    "kind": "SQL",
    "hint": "`WITH CategorySales AS (SELECT ...)` 구문으로 먼저 요약 테이블을 정의한 후 메인 쿼리에서 활용하세요.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_struct_field",
    "title": "중첩 데이터(Struct) 접근: 점 표기법",
    "body": "address 컬럼이 구조체(Struct: city, zipcode)로 되어 있습니다. 이 중 'city' 정보만 추출하여 별도 컬럼으로 만드세요. Parquet/Avro 데이터 소스에서 흔한 패턴입니다.",
    "schema": "users(name STRING, address STRUCT<city:STRING, zipcode:INT>)",
    "sample_rows": [
      "Alice | {city: 'Seoul', zipcode: 04524}",
      "Bob | {city: 'Busan', zipcode: 40210}"
    ],
    "difficulty": "Lv2 초급",
    "kind": "Python.Pyspark",
    "hint": "`F.col('address.city')`와 같이 점(dot) 표기법을 사용하여 구조체 내부 필드에 접근할 수 있습니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_salting_skew",
    "title": "데이터 편향(Skew) 해결: Salting 기법",
    "body": "특정 키(key='A')에 데이터가 90% 몰려있어 조인 시 해당 태스크만 멈춰있습니다(Straggler). 조인 키에 임의의 난수(Salt)를 추가하여 데이터를 강제로 분산시킨 후 조인하는 전략을 구상해 보세요.",
    "schema": "df_skew(key STRING, value INT)",
    "sample_rows": [
      "A | 1",
      "A | 2",
      "... (A repeats 1M times)",
      "B | 1"
    ],
    "difficulty": "Lv5 심화",
    "kind": "Python.Pyspark",
    "hint": "1. `F.concat(col('key'), F.lit('_'), F.rand())`로 키를 쪼갭니다. \n2. 상대 테이블은 해당 개수만큼 복제(explode)하여 조인 조건을 맞춥니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "python_list_comp_basic",
    "title": "리스트 컴프리헨션: 짝수만 제곱하기",
    "body": "숫자 리스트 `numbers`가 주어졌을 때, 짝수인 숫자만 골라서 그 값을 제곱한 새로운 리스트를 만드세요. `for` 루프를 쓰지 말고 리스트 컴프리헨션을 사용해야 합니다.",
    "schema": "numbers (List[int])",
    "sample_rows": [
      "[1, 2, 3, 4, 5] -> [4, 16]",
      "[10, 11, 12] -> [100, 144]"
    ],
    "difficulty": "Lv1 입문",
    "kind": "Python",
    "hint": "`[식 for 변수 in 리스트 if 조건]` 형태를 기억하세요. `x % 2 == 0`이 짝수 조건입니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "python_list_comp_string",
    "title": "리스트 컴프리헨션: 글자 수 필터링 및 변환",
    "body": "문자열 리스트 `words`에서 길이가 5 이상인 단어만 골라, 모두 대문자로 변환된 리스트를 생성하세요.",
    "schema": "words (List[str])",
    "sample_rows": [
      "['apple', 'cat', 'banana'] -> ['APPLE', 'BANANA']"
    ],
    "difficulty": "Lv1 입문",
    "kind": "Python",
    "hint": "문자열 길이 확인은 `len(w)`, 대문자 변환은 `.upper()`를 사용합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "python_def_sum_rows",
    "title": "함수(def) & 행 다루기: 2차원 리스트 행별 합계",
    "body": "2차원 리스트(행렬)를 입력받아, 각 행(row)의 합계를 담은 리스트를 반환하는 함수 `row_sums(matrix)`를 작성하세요.",
    "schema": "matrix (List[List[int]])",
    "sample_rows": [
      "[[1, 2], [3, 4]] -> [3, 7]",
      "[[1, 1, 1], [2, 2, 2]] -> [3, 6]"
    ],
    "difficulty": "Lv2 초급",
    "kind": "Python",
    "hint": "`for row in matrix`로 각 행을 꺼낸 뒤, `sum(row)`를 이용하면 쉽게 구할 수 있습니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "python_array_transpose",
    "title": "배열 다루기: 행과 열 바꾸기 (Transpose)",
    "body": "2차원 리스트 `matrix`의 행과 열을 뒤바꾼 새로운 행렬을 만드세요. (예: 2x3 행렬 -> 3x2 행렬). 이중 루프를 사용해도 좋고, 리스트 컴프리헨션을 사용해도 좋습니다.",
    "schema": "matrix (List[List[int]])",
    "sample_rows": [
      "[[1, 2, 3], [4, 5, 6]] -> [[1, 4], [2, 5], [3, 6]]"
    ],
    "difficulty": "Lv3 중급",
    "kind": "Python",
    "hint": "외부 루프는 열의 개수(`range(len(matrix[0]))`)만큼 돌고, 내부에서 각 행의 `i`번째 요소를 가져옵니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "python_algo_factorial",
    "title": "알고리즘(Loop): 팩토리얼 계산",
    "body": "정수 `n`을 입력받아 `n!` (팩토리얼) 값을 반환하는 함수 `factorial(n)`을 작성하세요. 재귀함수가 아닌 `for` 또는 `while` 루프를 사용해 구현하세요.",
    "schema": "n (int)",
    "sample_rows": [
      "5 -> 120 (1*2*3*4*5)",
      "3 -> 6"
    ],
    "difficulty": "Lv1 입문",
    "kind": "Python",
    "hint": "초기값을 1로 설정(`result = 1`)하고, 1부터 n까지 반복하며 계속 곱해줍니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "python_algo_count_dict",
    "title": "알고리즘 & 딕셔너리: 단어 빈도수 세기",
    "body": "단어들이 담긴 리스트 `words`를 입력받아, 각 단어가 몇 번 등장했는지 세어 `{단어: 횟수}` 형태의 딕셔너리로 반환하는 함수 `count_words(words)`를 작성하세요.",
    "schema": "words (List[str])",
    "sample_rows": [
      "['apple', 'banana', 'apple'] -> {'apple': 2, 'banana': 1}"
    ],
    "difficulty": "Lv2 초급",
    "kind": "Python",
    "hint": "빈 딕셔너리 `{}`를 만들고, 리스트를 루프 돌면서 키가 있으면 +1, 없으면 1로 초기화합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "python_list_slice_rotate",
    "title": "배열 슬라이싱: 리스트 회전시키기",
    "body": "리스트 `nums`와 정수 `k`가 주어질 때, 리스트의 요소를 오른쪽으로 `k`번 회전시킨 결과를 반환하는 함수 `rotate_list(nums, k)`를 작성하세요. 슬라이싱 기능을 활용하면 루프 없이 한 줄로 가능합니다.",
    "schema": "nums (List[int]), k (int)",
    "sample_rows": [
      "nums=[1, 2, 3, 4, 5], k=2 -> [4, 5, 1, 2, 3]"
    ],
    "difficulty": "Lv3 중급",
    "kind": "Python",
    "hint": "`nums[-k:]`는 뒤에서 k개, `nums[:-k]`는 앞의 나머지 부분입니다. 이 둘을 더하면 회전된 결과가 됩니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "python_algo_prime",
    "title": "알고리즘(Loop): 소수(Prime) 판별 함수",
    "body": "정수 `n`을 입력받아 소수이면 `True`, 아니면 `False`를 반환하는 함수 `is_prime(n)`을 작성하세요. 루프를 사용하여 2부터 `n-1`까지 나누어 떨어지는 수가 있는지 확인해야 합니다.",
    "schema": "n (int)",
    "sample_rows": [
      "7 -> True",
      "10 -> False"
    ],
    "difficulty": "Lv2 초급",
    "kind": "Python",
    "hint": "반복문 도중 `n % i == 0`인 경우가 한 번이라도 발견되면 즉시 `return False`하고 종료합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "python_list_flatten",
    "title": "리스트 컴프리헨션: 2차원 리스트 평탄화(Flatten)",
    "body": "2차원 리스트(리스트 안의 리스트)를 1차원 리스트로 쭉 펼치는 함수 `flatten(matrix)`를 리스트 컴프리헨션을 사용해 작성하세요.",
    "schema": "matrix (List[List[int]])",
    "sample_rows": [
      "[[1, 2], [3, 4], [5]] -> [1, 2, 3, 4, 5]"
    ],
    "difficulty": "Lv3 중급",
    "kind": "Python",
    "hint": "이중 `for`문 순서대로 적으면 됩니다. `for row in matrix`가 먼저 오고, 그 뒤에 `for val in row`가 옵니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "python_algo_max_index",
    "title": "배열 다루기: 최댓값과 그 위치 찾기",
    "body": "숫자 리스트 `nums`에서 가장 큰 값과 그 값의 인덱스(위치)를 튜플 `(max_val, index)` 형태로 반환하는 함수 `find_max_info(nums)`를 작성하세요. 내장함수 `max()`나 `index()`를 쓰지 않고 루프로 구현해보세요.",
    "schema": "nums (List[int])",
    "sample_rows": [
      "[10, 50, 30] -> (50, 1)"
    ],
    "difficulty": "Lv2 초급",
    "kind": "Python",
    "hint": "`for i, val in enumerate(nums):`를 사용하여 인덱스와 값을 동시에 얻고, 현재 최댓값보다 크면 갱신합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_python_list_comp_rename",
    "title": "List Comprehension: 모든 컬럼명 소문자로 변경하기",
    "body": "데이터프레임의 컬럼명이 대소문자가 섞여 있어('UserID', 'CreateDATE') 다루기 불편합니다. 파이썬의 리스트 컴프리헨션을 사용하여 모든 컬럼명을 소문자로 바꾼 뒤, `toDF` 메서드를 사용해 한 번에 적용하세요.",
    "schema": "df(UserID STRING, CreateDATE DATE, Amount INT)",
    "sample_rows": [
      "user1 | 2024-01-01 | 100"
    ],
    "difficulty": "Lv2 초급",
    "kind": "Python.Pyspark",
    "hint": "`df.columns`는 파이썬 리스트를 반환합니다. 이를 리스트 컴프리헨션으로 가공하고, `df.toDF(*new_cols)`와 같이 언패킹(`*`)하여 전달하는 패턴은 국룰입니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_python_unpacking_select",
    "title": "Unpacking(*): 리스트에 담긴 컬럼들만 선택하기",
    "body": "분석에 필요한 컬럼 이름들이 파이썬 리스트 `target_cols = ['name', 'age']`에 담겨 있습니다. 이 리스트를 `select` 함수에 직접 전달하면 에러가 납니다. 리스트의 요소들을 풀어서(Unpacking) 전달하는 파이썬 문법을 사용하세요.",
    "schema": "df(name STRING, age INT, address STRING, phone STRING)",
    "sample_rows": [
      "Alice | 25 | Seoul | 010..."
    ],
    "difficulty": "Lv1 입문",
    "kind": "Python.Pyspark",
    "hint": "함수 인자로 리스트를 바로 넣는 대신, `*리스트이름`을 쓰면 리스트 껍질을 벗겨서 알맹이만 `arg1, arg2, ...` 형태로 전달합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_python_udf_def_logic",
    "title": "Def & UDF: 복잡한 점수 계산 로직 적용",
    "body": "단순한 사칙연산이 아니라, 비즈니스 로직이 포함된 점수 계산이 필요합니다. 파이썬 함수 `calculate_score(purchase, visits)`를 정의하고(구매액/방문수 비율 계산, 0으로 나누기 방지 등), 이를 UDF로 변환하여 적용하세요.",
    "schema": "df(user_id INT, purchase INT, visits INT)",
    "sample_rows": [
      "1 | 10000 | 5 -> 2000.0",
      "2 | 0 | 0 -> 0.0"
    ],
    "difficulty": "Lv3 중급",
    "kind": "Python.Pyspark",
    "hint": "Spark SQL만으로 복잡한 `if-else`나 예외처리를 하긴 어렵습니다. 이럴 때 파이썬 함수(`def`)를 짜고 `udf`로 감싸서 사용합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_python_lambda_udf",
    "title": "Lambda & UDF: 일회용 함수로 문자열 가공",
    "body": "email 컬럼에서 '@' 앞의 아이디만 추출하고 싶습니다. 별도로 `def`를 선언하기엔 너무 간단한 로직입니다. 파이썬의 익명 함수 `lambda`를 사용하여 한 줄짜리 UDF를 만들고 적용하세요.",
    "schema": "df(email STRING)",
    "sample_rows": [
      "alice@company.com -> alice"
    ],
    "difficulty": "Lv2 초급",
    "kind": "Python.Pyspark",
    "hint": "`lambda 입력변수: 반환값` 형식을 사용합니다. `split` 같은 파이썬 문자열 메서드를 Spark 안에서 쓸 수 있게 해줍니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_python_dict_loop_rename",
    "title": "Dict Loop: 매핑 사전을 이용한 컬럼명 일괄 변경",
    "body": "시스템 컬럼명과 한글 컬럼명이 매핑된 딕셔너리 `col_map = {'nm': '이름', 'ag': '나이'}`가 있습니다. `for` 루프와 `withColumnRenamed`를 사용하여 딕셔너리에 정의된 대로 컬럼 이름을 모두 변경하세요.",
    "schema": "df(nm STRING, ag INT)",
    "sample_rows": [
      "Alice | 25"
    ],
    "difficulty": "Lv2 초급",
    "kind": "Python.Pyspark",
    "hint": "딕셔너리의 `.items()`를 순회하며 `df` 변수를 계속 덮어쓰는(update) 방식은 PySpark 코드 작성 시 흔한 패턴입니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_python_f_string_sql",
    "title": "f-string: 동적 SQL 쿼리 생성",
    "body": "테이블 이름 `table_name = 'sales_2024'`와 기준 금액 `min_amount = 1000`이 변수로 주어집니다. 파이썬의 f-string을 사용하여 `SELECT * FROM sales_2024 WHERE amount >= 1000` 형태의 쿼리 문자열을 생성하고 `spark.sql()`로 실행하세요.",
    "schema": "N/A (Spark SQL 실행)",
    "sample_rows": [],
    "difficulty": "Lv1 입문",
    "kind": "Python.Pyspark",
    "hint": "SQL 쿼리도 결국 문자열입니다. 파이썬 변수를 쿼리 중간에 꽂아 넣을 때 f-string이 가장 가독성이 좋습니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_python_list_comp_filter",
    "title": "List Comprehension: 특정 타입의 컬럼만 골라내기",
    "body": "데이터프레임 `df.dtypes`를 확인하면 `('col_name', 'string')` 형태의 튜플 리스트가 나옵니다. 리스트 컴프리헨션을 사용하여 데이터 타입이 'int'인 컬럼의 이름만 리스트로 추출하세요.",
    "schema": "df(name STRING, age INT, score INT)",
    "sample_rows": [
      "dtypes -> [('name', 'string'), ('age', 'int'), ('score', 'int')]"
    ],
    "difficulty": "Lv2 초급",
    "kind": "Python.Pyspark",
    "hint": "`for c, t in df.dtypes` 처럼 튜플을 언패킹하며 루프를 돌고, `if` 조건으로 필터링하는 전형적인 파이썬 패턴입니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_python_try_except",
    "title": "Try-Except: 파일 로드 시 예외 처리",
    "body": "데이터 파일 경로 `path`가 주어집니다. 파일을 읽어오되(`spark.read.csv`), 파일이 없거나 에러가 발생하면 \"파일을 찾을 수 없습니다\"를 출력하고 빈 데이터프레임을 생성하는 안전한 코드를 작성하세요.",
    "schema": "N/A",
    "sample_rows": [],
    "difficulty": "Lv2 초급",
    "kind": "Python.Pyspark",
    "hint": "데이터 파이프라인은 언제든 깨질 수 있습니다. `try-except` 블록으로 에러 상황을 우아하게(Graceful) 처리하는 것은 엔지니어의 기본 소양입니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_python_set_operations",
    "title": "Set 연산: 두 데이터프레임의 공통 컬럼 찾기",
    "body": "두 개의 데이터프레임 `df1`과 `df2`가 있습니다. 파이썬의 집합(Set) 자료형과 교집합 연산자(`&`)를 사용하여 두 데이터프레임에 공통으로 존재하는 컬럼명 리스트를 구하세요.",
    "schema": "df1(id, name, age), df2(id, address, phone)",
    "sample_rows": [
      "공통 컬럼 -> ['id']"
    ],
    "difficulty": "Lv1 입문",
    "kind": "Python.Pyspark",
    "hint": "리스트를 `set()`으로 변환하면 교집합(`&`), 차집합(`-`), 합집합(`|`)을 매우 쉽게 구할 수 있습니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_python_assert",
    "title": "Assert: 데이터 검증(Sanity Check)",
    "body": "데이터 가공이 끝난 후, 결과 데이터프레임 `result_df`의 행 개수가 0이면 안 된다는 조건을 걸고 싶습니다. 파이썬의 `assert` 문을 사용하여 행 개수가 0일 때 에러를 발생시키는 코드를 작성하세요.",
    "schema": "result_df(...)",
    "sample_rows": [],
    "difficulty": "Lv1 입문",
    "kind": "Python.Pyspark",
    "hint": "`assert 조건, 에러메시지` 형태입니다. 조건이 False면 프로그램이 즉시 중단되며 에러를 뿜습니다. 데이터 품질 체크에 필수적입니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_python_strip_columns",
    "title": "List Comp & String: 컬럼명 공백 제거",
    "body": "CSV를 읽었더니 컬럼명 앞뒤에 공백이 섞여 있습니다(예: ' user_id ', ' name'). 파이썬의 문자열 메서드 `.strip()`과 리스트 컴프리헨션을 사용하여 깔끔한 컬럼명 리스트를 만들고, `toDF`로 적용하세요.",
    "schema": "df(' user_id ', ' name')",
    "sample_rows": [
      "1 | Alice"
    ],
    "difficulty": "Lv1 입문",
    "kind": "Python.Pyspark",
    "hint": "문자열 `s.strip()`은 양쪽 공백을 제거합니다. `[c.strip() for c in df.columns]` 패턴은 데이터 로드 직후 국룰입니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_python_zip_rename",
    "title": "Zip Loop: 두 리스트를 엮어서 컬럼명 변경",
    "body": "현재 컬럼명 리스트 `old_cols = ['a', 'b']`와 바꿀 한글명 리스트 `new_cols = ['이름', '나이']`가 있습니다. 파이썬의 `zip()`을 사용하여 두 리스트를 쌍으로 묶은 뒤, 루프를 돌며 컬럼명을 변경하세요.",
    "schema": "df(a, b)",
    "sample_rows": [
      "Alice | 25"
    ],
    "difficulty": "Lv2 초급",
    "kind": "Python.Pyspark",
    "hint": "`zip(list_a, list_b)`는 두 리스트의 요소를 순서대로 튜플 `(a[0], b[0]), ...`로 묶어줍니다. 매핑 작업에 필수입니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_python_kwargs_options",
    "title": "Dict Unpacking(**): 읽기 옵션 한 번에 넣기",
    "body": "CSV를 읽을 때 옵션이 많습니다(header=True, inferSchema=True, sep=','). 이 옵션들을 `read_opts`라는 딕셔너리에 담아두고, `spark.read.options()` 함수에 **언패킹(kwargs)**하여 전달하세요.",
    "schema": "N/A",
    "sample_rows": [],
    "difficulty": "Lv2 초급",
    "kind": "Python.Pyspark",
    "hint": "함수에 `**딕셔너리`를 넣으면, 딕셔너리의 키=값 쌍이 함수의 인자(keyword arguments)로 풀려서 들어갑니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_python_dict_get_default",
    "title": "Dict Get: 매핑 실패 시 기본값 사용 (UDF)",
    "body": "코드 변환용 딕셔너리 `code_map = {'KR': 'Korea', 'US': 'USA'}`가 있습니다. 국가 코드를 입력받아 이름을 반환하되, 딕셔너리에 없는 코드는 'Unknown'을 반환하는 함수를 `def`로 짜고 UDF로 적용하세요.",
    "schema": "df(code STRING)",
    "sample_rows": [
      "KR -> Korea",
      "JP -> Unknown"
    ],
    "difficulty": "Lv2 초급",
    "kind": "Python.Pyspark",
    "hint": "`dict[key]`는 키가 없으면 에러가 나지만, `dict.get(key, default)`는 안전하게 기본값을 반환합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_python_enumerate_columns",
    "title": "Enumerate: 인덱스와 함께 루프 돌기",
    "body": "컬럼명이 중복되거나 의미 없을 때, 순서대로 번호를 붙이고 싶습니다. `df.columns`를 루프 돌되, `enumerate()`를 사용하여 'col_0', 'col_1', 'col_2'로 이름을 변경하세요.",
    "schema": "df(x, y, z)",
    "sample_rows": [
      "..."
    ],
    "difficulty": "Lv2 초급",
    "kind": "Python.Pyspark",
    "hint": "`enumerate(리스트)`는 `(0, 첫번째값), (1, 두번째값)...` 순서로 인덱스와 값을 동시에 뱉어줍니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_python_string_slicing",
    "title": "String Slicing: 날짜 문자열 쪼개기 (Lambda)",
    "body": "`YYYYMMDD` 형태의 문자열(예: '20240101')에서 연도(앞 4자리)만 추출하고 싶습니다. 복잡한 날짜 함수 대신, 파이썬의 문자열 슬라이싱 기능을 `lambda` UDF로 만들어 해결하세요.",
    "schema": "df(date_str STRING)",
    "sample_rows": [
      "20240101 -> 2024"
    ],
    "difficulty": "Lv1 입문",
    "kind": "Python.Pyspark",
    "hint": "문자열 `s`에서 `s[:4]`는 처음부터 4번째 인덱스 전까지 자릅니다. 파이썬의 가장 강력한 기능 중 하나입니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_python_truthy_check",
    "title": "Truthy/Falsy: 리스트가 비었는지 확인하기",
    "body": "데이터 처리 중 에러가 발생하여 `error_list`에 에러 메시지가 담겼습니다. 이 리스트가 **비어있지 않을 때만** 경고 로그를 출력하려고 합니다. 파이썬스럽게 조건문을 작성하세요.",
    "schema": "N/A (로직 문제)",
    "sample_rows": [],
    "difficulty": "Lv1 입문",
    "kind": "Python.Pyspark",
    "hint": "`if len(error_list) > 0:` 대신 `if error_list:`를 씁니다. 빈 리스트 `[]`는 False, 내용이 있으면 True로 취급됩니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_python_replace_string",
    "title": "String Replace: 파일 경로 수정",
    "body": "S3 경로가 담긴 리스트 `paths`가 있는데, 프로토콜이 `s3n://`으로 되어 있습니다. 이를 모두 `s3a://`로 바꾸는 리스트 컴프리헨션을 작성하세요.",
    "schema": "paths (List[str])",
    "sample_rows": [
      "['s3n://bucket/a', 's3n://bucket/b']"
    ],
    "difficulty": "Lv1 입문",
    "kind": "Python.Pyspark",
    "hint": "문자열 메서드 `.replace('찾을값', '바꿀값')`을 사용합니다. 단순 치환에 가장 많이 쓰입니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_python_in_operator",
    "title": "IN Operator: 금지어 포함 여부 확인",
    "body": "금지어 리스트 `bad_words = ['error', 'fail']`가 있습니다. 로그 메시지(문자열) 내에 금지어 중 하나라도 포함되어 있는지 확인하는 함수를 작성하세요. (Spark 함수가 아닌 파이썬 `in` 연산자 활용)",
    "schema": "N/A (UDF 로직)",
    "sample_rows": [],
    "difficulty": "Lv2 초급",
    "kind": "Python.Pyspark",
    "hint": "파이썬에서 `'a' in 'abc'`는 True입니다. 루프와 `in`을 결합하여 부분 문자열 검색을 구현합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_python_split_unpack",
    "title": "Split & Indexing: 이메일 도메인 추출",
    "body": "이메일 주소 'user@gmail.com'을 `@` 기준으로 쪼갠 후, 뒤쪽 도메인('gmail.com')만 가져오고 싶습니다. `split` 함수와 인덱싱을 `lambda` UDF로 구현하세요.",
    "schema": "df(email STRING)",
    "sample_rows": [
      "a@b.com -> b.com"
    ],
    "difficulty": "Lv1 입문",
    "kind": "Python.Pyspark",
    "hint": "`s.split('@')`은 리스트 `['user', 'gmail.com']`을 반환합니다. `[1]` 또는 `[-1]`로 뒤쪽 요소를 가져옵니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_python_type_check",
    "title": "Isinstance: 데이터 타입 방어 로직",
    "body": "함수 `process_data(value)`를 만들 때, 입력된 `value`가 정수(int)일 때만 처리하고, 문자열이나 다른 타입이면 None을 반환하도록 방어 코드를 작성하세요.",
    "schema": "N/A",
    "sample_rows": [],
    "difficulty": "Lv2 초급",
    "kind": "Python.Pyspark",
    "hint": "`type(value) == int`보다 `isinstance(value, int)`가 권장됩니다. 데이터 파이프라인에서 잘못된 타입이 들어오는 것을 막을 때 씁니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_python_zfill",
    "title": "String Padding: 월(Month) 0 채우기",
    "body": "숫자형으로 된 월(month) 데이터(1, 2, ..., 12)를 문자열 '01', '02', ..., '12' 형태로 변환해야 합니다. 파이썬 문자열 메서드 `.zfill()`을 사용하여 2자리로 맞추는 Lambda UDF를 작성하세요.",
    "schema": "df(month INT)",
    "sample_rows": [
      "1 -> '01', 12 -> '12'"
    ],
    "difficulty": "Lv1 입문",
    "kind": "Python.Pyspark",
    "hint": "숫자를 먼저 `str(x)`로 문자로 바꾼 뒤 `.zfill(2)`를 호출하면 앞에 0을 채워줍니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_python_join_list",
    "title": "String Join: 리스트를 문자열로 합치기",
    "body": "가공 결과가 리스트 `['Seoul', 'Busan', 'Jeju']`로 나왔습니다. 이를 콤마(,)로 구분된 하나의 문자열 \"Seoul,Busan,Jeju\"로 합쳐서 DB에 저장하려고 합니다. 파이썬 문자열 메서드를 사용하세요.",
    "schema": "cities (List[str])",
    "sample_rows": [],
    "difficulty": "Lv1 입문",
    "kind": "Python.Pyspark",
    "hint": "`'구분자'.join(리스트)` 형태입니다. 리스트를 문자열로 직렬화할 때 가장 많이 씁니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_python_dict_comp",
    "title": "Dict Comprehension: 키-값 뒤집기",
    "body": "코드 매핑 딕셔너리 `mapping = {'A': 1, 'B': 2}`가 있는데, 반대로 숫자로 문자를 찾고 싶어 `{1: 'A', 2: 'B'}` 형태로 뒤집으려 합니다. 딕셔너리 컴프리헨션을 사용하세요.",
    "schema": "N/A",
    "sample_rows": [],
    "difficulty": "Lv2 초급",
    "kind": "Python.Pyspark",
    "hint": "리스트 컴프리헨션과 비슷하지만 중괄호 `{}`를 쓰고 `key: value` 형태로 작성합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "pyspark_python_none_check_udf",
    "title": "None Check: UDF 내부의 결측치 방어",
    "body": "UDF로 문자열 길이를 잴 때, 값이 `None`이면 에러가 납니다. 입력 `x`가 `None`이면 0을, 아니면 길이를 반환하는 안전한 Lambda 식을 작성하세요.",
    "schema": "df(text STRING)",
    "sample_rows": [
      "NULL -> 0"
    ],
    "difficulty": "Lv2 초급",
    "kind": "Python.Pyspark",
    "hint": "파이썬의 삼항 연산자 `값 if 조건 else 다른값`을 활용합니다. `if x:`는 x가 None이거나 빈 문자열이 아님을 체크합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "python_basic_slicing_udf",
    "title": "문자열 슬라이싱: 앞자리만 자르기",
    "body": "주민등록번호나 ID의 앞 6자리만 필요합니다. 복잡한 함수 정의 없이, 파이썬의 슬라이싱 문법 `[:6]`을 사용하는 `lambda` 함수를 UDF로 만들어 적용하세요.",
    "schema": "df(personal_id STRING)",
    "sample_rows": [
      "900101-1234567 -> 900101"
    ],
    "difficulty": "Lv1 입문",
    "kind": "Python",
    "hint": "파이썬에서 `문자열[:n]`은 처음부터 n번째 글자 앞까지 자릅니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "python_basic_split_last",
    "title": "문자열 쪼개기: 파일 확장자 추출",
    "body": "파일 경로에서 확장자(예: txt, csv)만 가져오고 싶습니다. 점(`.`)을 기준으로 쪼갠(`split`) 후, 리스트의 **맨 마지막 요소**를 가져오는 파이썬 인덱싱 `-1`을 활용하세요.",
    "schema": "df(filepath STRING)",
    "sample_rows": [
      "/data/users.csv -> csv",
      "report.pdf -> pdf"
    ],
    "difficulty": "Lv1 입문",
    "kind": "Python",
    "hint": "`x.split('.')`의 결과는 리스트입니다. `[-1]`은 리스트의 마지막 요소를 의미합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "python_basic_ternary_op",
    "title": "삼항 연산자: 한 줄짜리 If-Else",
    "body": "점수(`score`)가 60 이상이면 'Pass', 아니면 'Fail'을 반환하고 싶습니다. `def`와 `if-else` 블록을 길게 쓰지 말고, 파이썬의 **한 줄 if문(삼항 연산자)**을 사용하여 `lambda` UDF를 만드세요.",
    "schema": "df(score INT)",
    "sample_rows": [
      "80 -> Pass",
      "50 -> Fail"
    ],
    "difficulty": "Lv1 입문",
    "kind": "Python",
    "hint": "`값1 if 조건 else 값2` 형식을 사용합니다. 파이썬에서 가장 자주 쓰이는 숏컷 중 하나입니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "python_basic_replace",
    "title": "문자열 치환: 특수문자 제거",
    "body": "전화번호에 포함된 하이픈(`-`)을 모두 없애고 숫자만 남기고 싶습니다. 파이썬 문자열의 `.replace()` 메서드를 사용하는 UDF를 작성하세요.",
    "schema": "df(phone STRING)",
    "sample_rows": [
      "010-1234-5678 -> 01012345678"
    ],
    "difficulty": "Lv1 입문",
    "kind": "Python",
    "hint": "`문자열.replace('찾을값', '바꿀값')`을 사용합니다. 바꿀 값에 빈 문자열 `''`을 넣으면 삭제 효과가 납니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "python_basic_f_string_udf",
    "title": "F-String: 단위 붙이기",
    "body": "몸무게 데이터가 숫자로 되어있는데, 출력용으로 뒤에 'kg' 단위를 붙이고 싶습니다. 파이썬의 **f-string**을 사용하여 `lambda` UDF를 만드세요.",
    "schema": "df(weight DOUBLE)",
    "sample_rows": [
      "70.5 -> 70.5kg"
    ],
    "difficulty": "Lv1 입문",
    "kind": "Python",
    "hint": "`f'{변수}kg'` 형태로 작성하면 변수 값이 문자열 안에 예쁘게 삽입됩니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "python_basic_upper_lower",
    "title": "대소문자 변환: 무조건 소문자로",
    "body": "사용자 입력값이 대문자, 소문자 섞여 있어 검색이 어렵습니다. 파이썬 문자열 메서드 `.lower()`를 사용하여 입력값을 모두 소문자로 통일하는 UDF를 작성하세요.",
    "schema": "df(input_text STRING)",
    "sample_rows": [
      "PySpark -> pyspark",
      "PYTHON -> python"
    ],
    "difficulty": "Lv1 입문",
    "kind": "Python",
    "hint": "`x.upper()`는 대문자, `x.lower()`는 소문자로 변환합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "python_basic_round",
    "title": "숫자 반올림: 소수점 정리",
    "body": "계산된 평점이 소수점 10자리까지 나와서 지저분합니다. 파이썬 내장 함수 `round()`를 사용하여 소수점 둘째 자리까지만 남기는 UDF를 작성하세요.",
    "schema": "df(rating DOUBLE)",
    "sample_rows": [
      "4.56789 -> 4.57"
    ],
    "difficulty": "Lv1 입문",
    "kind": "Python",
    "hint": "`round(숫자, 자릿수)` 함수를 사용합니다. `round(x, 2)`는 둘째 자리까지 반올림합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "python_basic_in_operator",
    "title": "포함 여부 확인: in 연산자",
    "body": "주소(`address`) 문자열 안에 'Seoul'이라는 단어가 포함되어 있는지 확인하여 True/False를 반환하고 싶습니다. 파이썬의 `in` 키워드를 사용하는 UDF를 작성하세요.",
    "schema": "df(address STRING)",
    "sample_rows": [
      "Gangnam-gu, Seoul -> True",
      "Busan, Korea -> False"
    ],
    "difficulty": "Lv1 입문",
    "kind": "Python",
    "hint": "`'찾을단어' in 문자열변수` 형태로 작성하면 결과는 `True` 또는 `False`가 됩니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "python_basic_type_cast",
    "title": "형변환: 문자를 숫자로 (int)",
    "body": "숫자로 된 문자열 \"007\"을 정수 `7`로 바꾸고 싶습니다. 파이썬 내장 함수 `int()`를 사용하여 형변환을 수행하는 UDF를 작성하세요.",
    "schema": "df(code_str STRING)",
    "sample_rows": [
      "\"007\" -> 7",
      "\"100\" -> 100"
    ],
    "difficulty": "Lv1 입문",
    "kind": "Python",
    "hint": "`int(x)`는 문자열이나 실수를 정수로 변환해줍니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "python_basic_none_check",
    "title": "None 체크: 안전한 길이 구하기",
    "body": "문자열의 길이를 구하는 `len()` 함수를 쓰고 싶은데, 데이터에 `None`(NULL)이 섞여 있어 에러가 걱정됩니다. `x`가 `None`이면 0을, 아니면 `len(x)`를 반환하는 안전한 로직을 작성하세요.",
    "schema": "df(name STRING)",
    "sample_rows": [
      "Alice -> 5",
      "NULL -> 0"
    ],
    "difficulty": "Lv1 입문",
    "kind": "Python",
    "hint": "`if x is not None`은 파이썬에서 가장 정석적인 NULL 체크 방식입니다. (또는 간단히 `if x:`를 쓰기도 합니다)",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_basic_union_vs_union_all",
    "title": "집합 연산: 중복을 포함할까?",
    "body": "두 개의 테이블(A, B)에서 얻은 유저 ID 목록을 하나로 합치고 싶습니다. 단, A와 B 양쪽에 모두 존재하는 유저가 있다면 두 번 모두 출력되어야 합니다(중복 허용). 어떤 연산자를 써야 할까요?",
    "schema": "table_a(id INT), table_b(id INT)",
    "sample_rows": [
      "A: 1, 2 | B: 2, 3 -> Result: 1, 2, 2, 3"
    ],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "`UNION`은 중복을 제거(Unique)하지만, `UNION ALL`은 단순히 이어 붙여서 중복을 유지합니다. 성능도 `UNION ALL`이 더 빠릅니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_basic_join_inner",
    "title": "JOIN 기초: 교집합 구하기",
    "body": "주문 내역(orders)과 회원 정보(users)를 연결해서 조회하려 합니다. 탈퇴했거나 정보가 없는 회원의 주문은 제외하고, '두 테이블 모두에 데이터가 있는 경우'만 남기려면 어떤 JOIN을 써야 할까요?",
    "schema": "orders(user_id), users(user_id)",
    "sample_rows": [],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "양쪽 모두에 매칭되는 데이터만 가져오는 것은 `INNER JOIN`입니다. (그냥 `JOIN`이라고 써도 기본값은 INNER입니다)",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_basic_join_left",
    "title": "JOIN 기초: 주문 내역 보존하기",
    "body": "주문(orders) 테이블을 기준으로, 회원(users) 정보를 붙이려고 합니다. 회원이 탈퇴해서 정보가 없더라도 주문 기록은 그대로 나와야 합니다. 이때 사용하는 JOIN은?",
    "schema": "orders(o_id, u_id), users(u_id, name)",
    "sample_rows": [
      "Order 1 | User A",
      "Order 2 | NULL (회원정보 없음)"
    ],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "왼쪽(기준) 테이블의 모든 행을 유지하고 오른쪽 테이블을 붙이는 것은 `LEFT JOIN`입니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_basic_string_trim",
    "title": "공백 제거: ' Alice '는 'Alice'가 아니다",
    "body": "사용자가 실수로 이름 앞뒤에 공백을 넣어 가입했습니다(' Alice '). 이를 'Alice'로 검색하려면 공백을 제거하는 함수를 써서 비교해야 합니다.",
    "schema": "users(name TEXT)",
    "sample_rows": [
      "' Alice ' -> 'Alice'"
    ],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "`TRIM()` 함수는 문자열 양쪽의 공백을 제거합니다. (`LTRIM`, `RTRIM`도 있습니다)",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_basic_string_upper",
    "title": "대소문자 무시 검색",
    "body": "저장된 데이터는 'Kim', 'kim', 'KIM' 등 제각각입니다. 대소문자 구분 없이 'kim'을 검색하려면 양쪽을 모두 대문자(혹은 소문자)로 맞춰서 비교해야 합니다.",
    "schema": "users(name TEXT)",
    "sample_rows": [],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "`UPPER(col)` 혹은 `LOWER(col)` 함수를 사용하여 통일한 뒤 비교합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_basic_length_check",
    "title": "문자열 길이: 비밀번호 길이 제한",
    "body": "비밀번호(password) 길이가 8자리 미만인 취약한 계정을 찾으려 합니다. 문자열의 길이를 반환하는 함수를 사용하세요.",
    "schema": "users(password TEXT)",
    "sample_rows": [],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "표준은 `LENGTH()`이고, SQL Server 등 일부는 `LEN()`을 사용합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_basic_substring_extract",
    "title": "문자열 자르기: 생년월일에서 연도만",
    "body": "주민번호나 생년월일 문자열('19900101')의 앞에서부터 4글자(연도)만 잘라내고 싶습니다.",
    "schema": "users(birth_str TEXT)",
    "sample_rows": [
      "'19900101' -> '1990'"
    ],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "`SUBSTRING(컬럼, 시작위치, 길이)` 또는 `LEFT(컬럼, 길이)`를 사용합니다. SQL의 문자열 인덱스는 보통 1부터 시작합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_basic_math_round",
    "title": "반올림: 소수점 제거",
    "body": "평균 점수가 85.6점일 때, 이를 반올림하여 86점으로 만들고 싶습니다.",
    "schema": "scores(avg_score DECIMAL)",
    "sample_rows": [],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "`ROUND(값, 소수점자리수)`를 씁니다. 정수로 만들려면 자리수에 0을 넣습니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_basic_between_dates",
    "title": "기간 조회: 1월의 데이터",
    "body": "주문일(order_date)이 2023년 1월 1일부터 1월 31일 사이인 데이터를 찾으려 합니다. `>=`와 `<=`를 써도 되지만, 더 가독성 좋은 연산자는 무엇일까요?",
    "schema": "orders(order_date DATE)",
    "sample_rows": [],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "`col BETWEEN 시작값 AND 종료값`을 사용합니다. (양쪽 끝값을 포함합니다)",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_basic_not_in_null_trap",
    "title": "NOT IN의 함정: NULL이 목록에 있다면?",
    "body": "제외할 ID 목록에 NULL이 하나라도 포함되어 있으면(`NOT IN (1, 2, NULL)`), 결과는 어떻게 될까요? (매우 중요한 개념 문제입니다)",
    "schema": "users(id INT)",
    "sample_rows": [],
    "difficulty": "Lv3 중급",
    "kind": "SQL",
    "hint": "`NOT IN`은 목록 중 하나라도 NULL이면 전체 결과가 Unknown이 되어버려 아무 데이터도 나오지 않습니다. `NOT EXISTS`를 쓰거나 NULL을 제거해야 합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_basic_exists_performance",
    "title": "존재 여부 확인: EXISTS",
    "body": "특정 조건을 만족하는 주문이 '하나라도 있는지' 확인하고 싶습니다. 전체 개수를 세는 `COUNT(*) > 0`보다 성능상 유리하고 '있으면 참'을 반환하는 연산자는?",
    "schema": "orders(user_id)",
    "sample_rows": [],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "`EXISTS`는 조건을 만족하는 첫 번째 행을 발견하면 즉시 탐색을 멈추고 True를 반환하므로 빠릅니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_basic_group_by_having_count",
    "title": "중복 찾기: 2번 이상 주문한 사람",
    "body": "주문 내역에서 주문 횟수가 2회 이상인 user_id만 뽑아내고 싶습니다. `GROUP BY`와 함께 써야 할 조건절은?",
    "schema": "orders(user_id)",
    "sample_rows": [],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "집계 결과(`COUNT`)에 대한 필터링은 `WHERE`가 아니라 `HAVING`에 써야 합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_basic_operator_precedence",
    "title": "논리 연산 순서: AND vs OR",
    "body": "`A AND B OR C` 와 `A AND (B OR C)`는 결과가 다릅니다. SQL에서 AND와 OR 중 우선순위가 더 높은 것은 무엇일까요?",
    "schema": "N/A",
    "sample_rows": [],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "곱셈이 덧셈보다 먼저인 것처럼, `AND`가 `OR`보다 먼저 실행됩니다. 헷갈리면 무조건 괄호`()`를 쓰세요.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_basic_select_distinct_col",
    "title": "고유한 조합 찾기: 부서와 직책",
    "body": "우리 회사에 존재하는 '부서(dept)'와 '직책(job)'의 모든 고유한 조합을 보고 싶습니다. (예: IT팀-개발자, IT팀-매니저)",
    "schema": "emp(dept, job)",
    "sample_rows": [],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "`DISTINCT` 뒤에 여러 컬럼을 적으면 그 컬럼들의 '조합'이 중복되지 않게 가져옵니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_basic_arithmetic_null",
    "title": "NULL과의 산술 연산",
    "body": "연봉(salary)이 5000이고 커미션(comm)이 NULL인 직원의 `salary + comm` 결과는 얼마일까요?",
    "schema": "emp(salary, comm)",
    "sample_rows": [
      "5000 + NULL = ?"
    ],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "NULL에 어떤 숫자를 더하거나 빼도 결과는 무조건 NULL입니다. 그래서 `COALESCE(comm, 0)` 처리가 필요합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_basic_cross_join",
    "title": "모든 경우의 수: 카테시안 곱",
    "body": "색상 테이블(Red, Blue)과 사이즈 테이블(S, M, L)을 결합하여 만들 수 있는 모든 옵션(Red-S, Red-M...)을 생성하고 싶습니다. 조건 없이 모든 행을 1:1로 결합하는 JOIN은?",
    "schema": "colors(name), sizes(code)",
    "sample_rows": [],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "`CROSS JOIN`은 두 테이블 행의 개수를 곱한 만큼의 결과를 만듭니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_basic_case_in_select",
    "title": "조건부 출력: 성별 코드 변환",
    "body": "DB에 성별이 'M', 'F'로 저장되어 있습니다. 조회할 때는 이를 '남성', '여성'으로 바꿔서 보여주고 싶습니다.",
    "schema": "users(gender CHAR(1))",
    "sample_rows": [],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "`CASE WHEN 조건 THEN 결과 ... END` 구문을 SELECT 절에 사용합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_basic_order_by_string_number",
    "title": "문자열 정렬의 함정: '10' vs '2'",
    "body": "숫자가 문자열(VARCHAR)로 저장된 컬럼을 정렬(`ORDER BY col`)하면, '1, 10, 2' 순서로 나옵니다. 이를 숫자 크기순('1, 2, 10')으로 정렬하려면?",
    "schema": "data(num_str VARCHAR)",
    "sample_rows": [],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "정렬 기준에서 타입을 숫자로 변환(`CAST`)해주어야 크기 비교가 올바르게 됩니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_basic_like_underscore",
    "title": "패턴 매칭: 정확히 3글자?",
    "body": "`LIKE` 연산자에서 `%`는 길이 상관없는 와일드카드지만, '정확히 한 글자'를 의미하는 와일드카드는 무엇일까요? (예: A로 시작하는 3글자 단어 찾기)",
    "schema": "words(w TEXT)",
    "sample_rows": [
      "Like 'A__'"
    ],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "언더스코어 `_`는 문자 한 개를 의미합니다. `LIKE 'A__'`는 A 뒤에 두 글자가 더 있는 3글자 문자열을 찾습니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_basic_date_add",
    "title": "날짜 더하기: 7일 후",
    "body": "오늘 날짜로부터 일주일(7일) 뒤의 날짜를 구하고 싶습니다. (함수 이름은 DB마다 조금 다르지만 일반적인 형태)",
    "schema": "N/A",
    "sample_rows": [],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "MySQL은 `DATE_ADD`, Postgres/Oracle은 `dt + INTERVAL '7' DAY`, SQL Server는 `DATEADD(day, 7, dt)`를 씁니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_basic_count_asterisk_vs_col",
    "title": "COUNT(*) vs COUNT(컬럼): NULL은 세나요?",
    "body": "테이블의 전체 행 개수를 세는 것과 특정 컬럼의 개수를 세는 것의 차이를 묻습니다. `email` 컬럼에 NULL이 포함되어 있을 때, NULL을 포함하지 않고 개수를 세려면 어떻게 해야 할까요?",
    "schema": "users(id INT, email TEXT)",
    "sample_rows": [
      "1 | a@test.com",
      "2 | NULL",
      "3 | b@test.com"
    ],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "`COUNT(*)`는 NULL 여부와 상관없이 무조건 행의 수를 셉니다. 반면 `COUNT(컬럼명)`은 해당 컬럼이 NULL인 행은 세지 않습니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_basic_distinct_count",
    "title": "중복 제거하고 세기: 고유 방문자 수",
    "body": "한 유저가 여러 번 방문했습니다. 중복을 제외하고 '실제 방문한 유저 수(UV)'를 구하려면 `COUNT` 안에 어떤 키워드를 넣어야 할까요?",
    "schema": "visits(user_id INT)",
    "sample_rows": [
      "1",
      "1",
      "2"
    ],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "`COUNT(DISTINCT 컬럼명)`을 사용하면 중복된 값을 하나로 쳐서 셉니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_basic_coalesce_usage",
    "title": "NULL 값 대체하기: 기본값 설정",
    "body": "주소(address) 정보가 없는 경우 'Unknown'이라고 출력하고 싶습니다. IFNULL이나 ISNULL은 DB마다 다르지만, 표준 SQL 함수인 이것을 사용하면 됩니다.",
    "schema": "users(name TEXT, address TEXT)",
    "sample_rows": [
      "Alice | NULL -> Unknown"
    ],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "`COALESCE(컬럼, 대체값)`은 컬럼이 NULL일 때 대체값을 반환합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_basic_order_by_multi",
    "title": "정렬 기준 여러 개: 성적순, 이름순",
    "body": "성적(score)이 높은 순서대로 정렬하되, 성적이 같으면 이름(name)의 가나다(알파벳) 순으로 정렬하세요.",
    "schema": "students(name TEXT, score INT)",
    "sample_rows": [],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "콤마(`,`)로 구분하여 순서대로 적습니다. `ORDER BY score DESC, name ASC` (ASC는 생략 가능)",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_basic_like_wildcard",
    "title": "문자열 패턴 찾기: 김씨 성을 가진 사람",
    "body": "이름이 'Kim'으로 시작하는 모든 사람을 찾으려 합니다. `=` 연산자가 아닌 패턴 매칭 연산자와 와일드카드(`%`)를 사용하세요.",
    "schema": "users(name TEXT)",
    "sample_rows": [
      "Kim Chulsu",
      "Lee Younghee"
    ],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "`WHERE name LIKE 'Kim%'`를 쓰면 Kim으로 시작하는 모든 문자열을 찾습니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_basic_cast_int_string",
    "title": "타입 변환: 숫자가 문자로 저장되었을 때",
    "body": "가격(price) 컬럼이 실수로 문자열(`VARCHAR`) 타입으로 저장되어 있습니다. 이를 숫자로 바꿔서 1000 이상인 것만 찾으려면 어떻게 변환해야 할까요?",
    "schema": "products(price_str TEXT)",
    "sample_rows": [
      "'500'",
      "'2000'"
    ],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "표준은 `CAST(컬럼 AS 타입)`입니다. 예: `CAST(price_str AS INTEGER) >= 1000`. (일부 DB는 `::INT` 지원)",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_basic_group_by_error",
    "title": "GROUP BY의 규칙: SELECT에 쓸 수 있는 컬럼",
    "body": "부서별 평균 연봉을 구하는 쿼리입니다. `SELECT dept, name, AVG(salary) FROM emp GROUP BY dept`를 실행하면 에러가 납니다. 왜일까요? 올바르게 고쳐보세요. (이름은 제외)",
    "schema": "emp(name TEXT, dept TEXT, salary INT)",
    "sample_rows": [],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "`GROUP BY`에 포함되지 않은 컬럼(name)은 집계 함수 없이 `SELECT` 절에 단독으로 올 수 없습니다. 부서별로 묶었는데 이름이 여러 개면 무엇을 출력할지 모르기 때문입니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_basic_having_vs_where",
    "title": "조건 필터링: 집계 후 결과 필터링",
    "body": "평균 점수가 80점 이상인 '반(Class)'만 조회하고 싶습니다. `WHERE AVG(score) >= 80`이라고 쓰면 에러가 납니다. 집계 결과에 조건을 걸 때는 무엇을 써야 할까요?",
    "schema": "scores(class TEXT, score INT)",
    "sample_rows": [],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "`WHERE`는 집계 전의 개별 행을 필터링하고, `HAVING`은 `GROUP BY`가 끝난 후의 집계 결과를 필터링합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_basic_datediff_today",
    "title": "날짜 차이: 오늘까지 며칠 지났나?",
    "body": "프로젝트 시작일(start_date)로부터 오늘(`CURRENT_DATE`)까지 며칠이 지났는지 계산하세요.",
    "schema": "projects(start_date DATE)",
    "sample_rows": [],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "미래(오늘)에서 과거(시작일)를 빼야 양수가 나옵니다. DB에 따라 순서가 `DATEDIFF(end, start)`입니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_basic_case_when_basic",
    "title": "조건문: 성적 등급 매기기",
    "body": "점수가 90 이상이면 'A', 아니면 'B'를 출력하는 컬럼을 만드세요.",
    "schema": "scores(score INT)",
    "sample_rows": [
      "95 -> A",
      "80 -> B"
    ],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "`CASE WHEN 조건 THEN 값 ELSE 값 END` 구문을 사용합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_basic_sum_over_basic",
    "title": "윈도우 함수 맛보기: 전체 합계 붙이기",
    "body": "각 직원의 정보 옆에 '전사 총 급여 합계'를 똑같이 붙여서 보여주고 싶습니다. `GROUP BY` 없이 하려면 윈도우 함수를 어떻게 써야 할까요?",
    "schema": "emp(name TEXT, salary INT)",
    "sample_rows": [
      "A | 100 | Total: 300",
      "B | 200 | Total: 300"
    ],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "`OVER()` 안에 아무것도 넣지 않으면 전체 데이터를 하나의 창(Window)으로 봅니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_basic_row_number_reset",
    "title": "순번 매기기: 그룹별로 1번부터 다시",
    "body": "반(Class)별로 학생들에게 번호를 매기고 싶습니다. A반 1, 2, 3번... B반 1, 2번... 처럼 그룹이 바뀔 때마다 번호가 리셋되게 하세요.",
    "schema": "students(class TEXT, name TEXT)",
    "sample_rows": [],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "`PARTITION BY`가 '그룹을 나누는 기준'이고 `ORDER BY`가 '순번을 매기는 순서'입니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_basic_lag_null",
    "title": "LAG의 첫 번째 값: 이전이 없으면?",
    "body": "첫 번째 행은 '이전 행'이 없습니다. 이때 `LAG` 함수는 무엇을 반환할까요? 그리고 이를 0으로 바꾸려면 어떻게 해야 할까요?",
    "schema": "sales(dt DATE, amount INT)",
    "sample_rows": [
      "1일: 100, Prev: NULL (or 0)"
    ],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "기본적으로 `NULL`을 반환합니다. `COALESCE`로 감싸거나, `LAG(col, 1, 0)` 처럼 3번째 인자에 기본값을 줍니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_basic_rank_concept",
    "title": "순위 함수: RANK vs ROW_NUMBER",
    "body": "점수가 같은 사람이 있을 때, `ROW_NUMBER`는 무조건 1, 2등으로 나누지만 `RANK`는 공동 1등(1, 1)을 줍니다. 공동 1등이 2명이면 그 다음 사람은 몇 등이 되나요?",
    "schema": "N/A",
    "sample_rows": [
      "1등, 1등, ?등"
    ],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "`RANK`는 앞의 인원수만큼 건너뜁니다. (1, 1 다음은 3). 건너뛰기 싫으면 `DENSE_RANK`를 씁니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_basic_null_comparison",
    "title": "NULL과 비교 연산: NULL = NULL ?",
    "body": "`WHERE col = NULL`이나 `WHERE NULL = NULL`은 참(True)일까요? SQL에서 NULL을 찾으려면 어떻게 해야 하는지 다시 확인합니다.",
    "schema": "test(col INT)",
    "sample_rows": [],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "SQL에서 NULL과의 모든 연산(`=`, `!=`, `+` 등)은 `Unknown(NULL)`입니다. 반드시 `IS NULL` 혹은 `IS NOT NULL`을 써야 합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_basic_date_extraction",
    "title": "날짜에서 정보 뽑기: 연도와 월",
    "body": "`2025-12-25` 같은 날짜 컬럼에서 '연도(2025)'와 '월(12)'만 숫자로 추출하고 싶습니다.",
    "schema": "orders(order_date DATE)",
    "sample_rows": [],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "대부분의 DB에서 `YEAR()`, `MONTH()` 함수를 지원합니다. (Postgres는 `EXTRACT(YEAR FROM ...)` 사용)",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_basic_window_vs_group",
    "title": "개념 확인: GROUP BY vs Partition By",
    "body": "데이터의 행(Row) 수가 줄어드는 것은 어느 것일까요? 1. `GROUP BY` 집계, 2. `OVER (PARTITION BY)` 윈도우 집계",
    "schema": "N/A",
    "sample_rows": [],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "`GROUP BY`는 그룹당 한 행으로 요약(압축)하지만, 윈도우 함수는 원래 행을 그대로 유지하면서 옆에 계산 결과만 붙입니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_basic_concat_string",
    "title": "문자열 합치기: 성 + 이름",
    "body": "`first_name`과 `last_name` 컬럼을 합쳐서 'Full Name'을 만들고 싶습니다. (띄어쓰기 한 칸 포함)",
    "schema": "users(first_name TEXT, last_name TEXT)",
    "sample_rows": [
      "Gildong | Hong -> Hong Gildong"
    ],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "MySQL은 `CONCAT(last_name, ' ', first_name)`, 표준 SQL이나 Oracle/Postgres는 `last_name || ' ' || first_name`을 씁니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_basic_in_usage",
    "title": "여러 값 필터링: OR 노가다 줄이기",
    "body": "status가 'Pending', 'Processing', 'Shipped' 중 하나인 주문을 찾을 때 `OR`를 3번 쓰는 대신 사용하는 연산자는?",
    "schema": "orders(status TEXT)",
    "sample_rows": [],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "`status IN ('A', 'B', 'C')` 형태로 씁니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_basic_avg_integer",
    "title": "정수 나눗셈 주의: 10 / 3 = ?",
    "body": "정수형 컬럼끼리 나누거나 평균을 구할 때, 소수점이 버려지는 DB(예: SQL Server, 일부 설정의 MySQL)가 있습니다. 소수점까지 정확히 구하려면 어떻게 해야 할까요?",
    "schema": "scores(math INT, eng INT)",
    "sample_rows": [
      "(10 + 11) / 2 -> 10.5 (Not 10)"
    ],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "둘 중 하나를 실수(Float/Decimal)로 바꿔줘야 합니다. 가장 쉬운 꼼수는 `col * 1.0`을 하는 것입니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_mom_growth_rate",
    "title": "MoM (Month-over-Month) 성장률 구하기",
    "body": "월별 매출 테이블이 있습니다. 이번 달 매출이 지난달 대비 몇 퍼센트 성장했는지 구하는 식을 작성하세요. `(이번달 - 지난달) / 지난달 * 100` 공식을 `LAG`를 써서 완성하세요.",
    "schema": "monthly_sales(ym DATE, amount DECIMAL)",
    "sample_rows": [
      "2023-01 | 100",
      "2023-02 | 120 -> 20%"
    ],
    "difficulty": "Lv3 중급",
    "kind": "SQL",
    "hint": "먼저 `LAG(amount) OVER (ORDER BY ym)`으로 지난달 매출을 가져온 뒤, 이를 분모와 분자에 배치하여 계산합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_first_day_of_month",
    "title": "날짜 정제: 월의 첫 날로 변환 (Truncation)",
    "body": "일별 데이터를 월별로 그룹핑하기 위해, 모든 날짜(`2023-01-25`)를 해당 월의 1일(`2023-01-01`)로 바꾸는 일반적인 패턴은 무엇일까요? (DB마다 함수는 다르지만, 문자열 포맷팅이나 날짜 연산 로직을 떠올려보세요)",
    "schema": "daily_logs(dt DATE)",
    "sample_rows": [],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "MySQL은 `DATE_FORMAT(dt, '%Y-%m-01')`, Oracle/Postgres는 `DATE_TRUNC('month', dt)`를 씁니다. 이를 통해 `GROUP BY` 기준을 만듭니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_count_window_running",
    "title": "누적 접속 횟수: N번째 방문 표시",
    "body": "유저가 접속할 때마다 '이것은 당신의 N번째 접속입니다'라고 알려주고 싶습니다. `COUNT`와 윈도우 함수를 조합하여 접속 순서를 카운트하세요.",
    "schema": "logins(user_id INT, visited_at TIMESTAMP)",
    "sample_rows": [
      "User1 | 10:00 -> 1",
      "User1 | 11:00 -> 2"
    ],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "`ROW_NUMBER`와 결과는 같지만 의미상 '누적 개수'이므로 `COUNT(*) OVER (ORDER BY ...)`를 쓸 수도 있습니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_lead_price_change_flag",
    "title": "가격 변동 탐지: 가격이 올랐나요?",
    "body": "상품의 가격 변경 이력 테이블에서, 직전 가격보다 현재 가격이 인상되었으면 'Up', 인하되었으면 'Down', 같으면 'Same'을 출력하는 CASE 문을 작성하세요. (과거->미래 순 정렬 가정)",
    "schema": "price_history(product_id INT, changed_at DATE, price INT)",
    "sample_rows": [],
    "difficulty": "Lv3 중급",
    "kind": "SQL",
    "hint": "`LAG(price) OVER (PARTITION BY product_id ORDER BY changed_at)`으로 이전 가격을 가져와서 현재 `price`와 비교합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_coalesce_display_name",
    "title": "화면 표시용 이름: 닉네임 > 실명 > ID",
    "body": "커뮤니티에서 작성자 이름을 보여줄 때 닉네임, 실명, 유저ID 순으로 존재하는 값을 보여주려 합니다. 3단계 우선순위를 `COALESCE`로 처리하세요. ID는 숫자기 때문에 문자열 변환이 필요할 수 있습니다.",
    "schema": "users(id INT, real_name TEXT, nickname TEXT)",
    "sample_rows": [],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "데이터 타입이 다르면(문자와 숫자) 에러가 날 수 있으니 `CAST(id AS CHAR)` 등으로 타입을 맞춰 `COALESCE`에 넣습니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_time_since_last_event",
    "title": "경과 시간 계산: 마지막 주문으로부터 며칠?",
    "body": "각 주문 건마다 '직전 주문으로부터 며칠 만에 주문했는지'를 계산하여 `days_since_prev` 컬럼을 만드세요.",
    "schema": "orders(user_id INT, order_date DATE)",
    "sample_rows": [
      "1일 -> NULL",
      "5일 -> 4"
    ],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "`DATEDIFF(order_date, LAG(order_date) OVER (...))`를 사용합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_window_sum_unbounded",
    "title": "전체 누적 합계 vs 그룹 누적 합계",
    "body": "부서별 누적 급여가 아니라, 회사 전체에서 연봉이 낮은 순서대로 누적 급여 합계를 구하고 싶습니다. `PARTITION BY`를 어떻게 처리해야 할까요?",
    "schema": "emp(salary INT)",
    "sample_rows": [],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "`PARTITION BY`를 생략하고 `ORDER BY`만 쓰면 전체 데이터를 대상으로 정렬 순서대로 누적합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_rank_bottom_n",
    "title": "하위 N명 추출: 성적 부진자 확인",
    "body": "성적이 낮은 순서대로 3명을 뽑고 싶습니다. 오름차순/내림차순 정렬만 바꾸면 `RANK` 함수로 간단히 해결됩니다.",
    "schema": "scores(student_id INT, score INT)",
    "sample_rows": [],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "`RANK() OVER (ORDER BY score ASC)`를 쓰면 점수가 낮은 사람이 1등이 됩니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_lag_string_change",
    "title": "상태 변경 이력: 값이 바뀐 순간만 찾기",
    "body": "주문의 배송 상태가 'Ready'에서 'Shipped'로 바뀌는 등, 상태값이 **이전과 달라진 순간**의 로그만 필터링하고 싶습니다. `LAG`값과 현재값이 다를 때를 조건으로 거세요.",
    "schema": "logs(order_id INT, status TEXT, updated_at TIMESTAMP)",
    "sample_rows": [
      "Ready (유지) -> 제외",
      "Shipped (변경) -> 포함"
    ],
    "difficulty": "Lv3 중급",
    "kind": "SQL",
    "hint": "서브쿼리에서 `prev_status`를 구한 뒤, 외부 WHERE 절에서 `status <> prev_status` 조건을 사용합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_max_date_latest_action",
    "title": "최근 활동일: 유저별 마지막 접속일",
    "body": "유저 리스트 옆에 '이 유저의 마지막 접속일'을 붙여서, 현재 활동 중인지(Active) 판단하려 합니다. `GROUP BY` 없이 윈도우 함수로 최댓값을 붙이세요.",
    "schema": "users_log(user_id INT, login_dt DATE)",
    "sample_rows": [],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "`MAX(login_dt) OVER (PARTITION BY user_id)`를 쓰면 해당 유저의 로그 중 가장 최신 날짜가 모든 행에 복제됩니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_row_number_per_category_limit",
    "title": "카테고리별 최대 2개씩 추천 상품 뽑기",
    "body": "각 카테고리별로 인기가 많은 상품을 딱 2개씩만 메인 화면에 노출하고 싶습니다. `ROW_NUMBER`를 이용해 필터링 쿼리를 구상하세요.",
    "schema": "products(cat_id INT, product_id INT, view_count INT)",
    "sample_rows": [],
    "difficulty": "Lv3 중급",
    "kind": "SQL",
    "hint": "카테고리로 파티션을 나누고 조회수 내림차순으로 번호를 매긴 뒤, `WHERE rn <= 2`로 자릅니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_avg_null_handling",
    "title": "평균 계산의 함정: NULL은 분모에 포함될까?",
    "body": "점수 컬럼에 `100, NULL, 0` 세 개의 값이 있습니다. `AVG(score)`의 결과는 얼마일까요? (NULL 처리 방식을 이해하고 있는지 묻는 문제입니다)",
    "schema": "scores(val INT)",
    "sample_rows": [
      "100, NULL, 0"
    ],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "`AVG` 등 집계 함수는 NULL을 **없는 데이터** 취급합니다. 즉 `(100 + 0) / 2 = 50`이 됩니다. (NULL을 0으로 치려면 `COALESCE` 후 평균을 내야 해서 33.3이 됨)",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_datediff_tenure_classification",
    "title": "재직 기간 분류: 1년 미만, 3년 미만...",
    "body": "직원의 입사일로부터 현재까지의 일수를 구하고, CASE 문을 써서 'Newbie'(1년 미만), 'Junior'(3년 미만), 'Senior'(그 외)로 등급을 나누세요. (1년=365일 가정)",
    "schema": "employees(join_date DATE)",
    "sample_rows": [],
    "difficulty": "Lv3 중급",
    "kind": "SQL",
    "hint": "`DATEDIFF(CURRENT_DATE, join_date)`로 일수를 구한 뒤 `CASE WHEN` 조건절에 사용하여 분류합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_ntile_ab_test_bucket",
    "title": "A/B 테스트 버킷 나누기",
    "body": "전체 사용자를 무작위로 섞어서 2개의 그룹(A군, B군)으로 50:50 분할하고 싶습니다. `NTILE`을 사용하되, 정렬 기준을 랜덤으로 설정해보세요.",
    "schema": "users(user_id INT)",
    "sample_rows": [
      "Group 1 (50%)",
      "Group 2 (50%)"
    ],
    "difficulty": "Lv3 중급",
    "kind": "SQL",
    "hint": "`NTILE(2) OVER (ORDER BY RAND())` (MySQL) 또는 `ORDER BY NEWID()` (SQL Server) 등을 쓰면 랜덤하게 반으로 나뉩니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_count_distinct_window_trick",
    "title": "누적 고유 방문자 수 (Trick)",
    "body": "시간이 흐름에 따라 '지금까지 방문한 고유 유저 수(Cumulative Distinct Users)'를 구하는 것은 표준 SQL 윈도우 함수(`COUNT(DISTINCT) OVER`)로 지원되지 않는 경우가 많습니다. 대신 `DENSE_RANK`를 날짜+유저 조합에 쓰는 등의 우회 전략이 필요합니다. (개념적으로만 접근해보세요)",
    "schema": "visits(dt DATE, user_id INT)",
    "sample_rows": [],
    "difficulty": "Lv5 심화",
    "kind": "SQL",
    "hint": "보통은 윈도우 함수로 한 번에 못 구합니다. 매일매일 그 날짜까지의 데이터를 `GROUP BY`하는 서브쿼리를 날리거나 전용 함수(HyperLogLog 등)를 써야 합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_sum_window_range_frame",
    "title": "윈도우 프레임: 지난 3건의 합계 (행 기준)",
    "body": "최근 3건의 주문 금액 합계를 구하려 합니다. 날짜가 아니라 **행의 개수**를 기준으로 `ROWS` 프레임을 지정하세요.",
    "schema": "orders(amount INT)",
    "sample_rows": [],
    "difficulty": "Lv4 고급",
    "kind": "SQL",
    "hint": "`ROWS BETWEEN 2 PRECEDING AND CURRENT ROW`는 나를 포함해 총 3행을 의미합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_lead_next_purchase_gap",
    "title": "재구매 주기 분석: 다음 구매까지 걸린 시간",
    "body": "유저의 구매 내역에서, '이번 구매 후 다음 구매를 할 때까지 며칠이 걸렸는지'를 계산하여 유저들의 평균 재구매 주기를 파악하려 합니다.",
    "schema": "orders(user_id INT, order_date DATE)",
    "sample_rows": [],
    "difficulty": "Lv3 중급",
    "kind": "SQL",
    "hint": "`DATEDIFF(LEAD(order_date) OVER (...), order_date)`를 구하면 각 구매 건 사이의 공백 기간(Gap)이 나옵니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_first_value_initial_channel",
    "title": "최초 유입 채널 고정하기",
    "body": "유저가 여러 경로로 들어오지만, 성과 분석을 위해 '가장 처음에 들어왔던 채널'을 모든 로그에 기록해두고 싶습니다. `FIRST_VALUE`를 쓰세요.",
    "schema": "visits(user_id INT, ts TIMESTAMP, channel TEXT)",
    "sample_rows": [
      "10:00 FB -> Initial: FB",
      "12:00 Google -> Initial: FB"
    ],
    "difficulty": "Lv3 중급",
    "kind": "SQL",
    "hint": "파티션 내에서 시간순 정렬 후 첫 번째 값을 가져오면 됩니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_dense_rank_medals",
    "title": "올림픽 메달 순위: 동점자 처리",
    "body": "점수가 높은 순으로 금, 은, 동메달을 주려 합니다. 동점자는 모두 같은 메달을 받고, 그 다음 순위는 건너뛰지 않습니다. (예: 공동 금메달 2명이면 다음은 은메달). 적절한 순위 함수는?",
    "schema": "games(player TEXT, score INT)",
    "sample_rows": [],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "공동 등수 후 순위가 밀리지 않아야 하므로 `DENSE_RANK`가 적합합니다. (`RANK`를 쓰면 공동 금메달 뒤에 동메달이 나옴)",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_coalesce_search_filter_opt",
    "title": "선택적 필터링: 입력된 조건만 검색하기",
    "body": "사용자가 지역(`@region`)과 나이(`@age`) 중 하나만 입력하거나 둘 다 입력할 수 있습니다. 입력된 값(NULL이 아님)에 대해서만 필터링하고 싶을 때 `COALESCE`나 `OR`를 어떻게 쓸까요?",
    "schema": "users(region TEXT, age INT)",
    "sample_rows": [],
    "difficulty": "Lv4 고급",
    "kind": "SQL",
    "hint": "이는 `COALESCE`보다 `(@param IS NULL OR col = @param)` 패턴이 인덱스 활용 면에서 유리할 때가 많지만, `col = COALESCE(@param, col)` 형태도 논리적으로는 같습니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_sessionization_sum_case",
    "title": "세션 ID 만들기 1단계: 세션 끊기",
    "body": "웹 로그 분석에서 가장 중요한 '세션(Session)'을 정의하려 합니다. 이전 로그(`LAG`)와의 시간 차이가 30분(1800초) 이상이면 '새로운 세션(1)', 아니면 '기존 세션(0)'으로 표시하는 `is_new_session` 플래그를 만드세요.",
    "schema": "logs(user_id INT, ts TIMESTAMP)",
    "sample_rows": [
      "10:00 -> 1 (New)",
      "10:05 -> 0",
      "11:00 -> 1 (New, Gap > 30m)"
    ],
    "difficulty": "Lv4 고급",
    "kind": "SQL",
    "hint": "시간 차이가 조건보다 크면 1, 아니면 0을 반환합니다. 이 1과 0들의 누적 합(`SUM OVER`)을 구하면 그것이 곧 고유한 세션 ID가 됩니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_running_max_drawdown",
    "title": "MDD 계산 기초: 고점 대비 하락폭",
    "body": "주식 데이터에서 '지금까지의 최고가(Running Max)' 대비 현재 가격이 얼마나 떨어졌는지(Drawdown) 비율을 구하고 싶습니다. `MAX()` 윈도우 함수를 이용해 역대 최고가를 먼저 구하세요.",
    "schema": "stock(dt DATE, price DECIMAL)",
    "sample_rows": [
      "100 (Max 100) -> 0%",
      "90 (Max 100) -> -10%"
    ],
    "difficulty": "Lv3 중급",
    "kind": "SQL",
    "hint": "`MAX(price) OVER (ORDER BY dt)`는 현재 시점까지의 최대값을 반환합니다. 이를 분모로 활용하여 하락률을 계산합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_cohort_min_date",
    "title": "코호트 분석: 유저의 첫 구매월 붙이기",
    "body": "모든 구매 내역 옆에, 해당 유저가 '최초로 구매했던 달(Cohort Month)'을 붙여서 비교 분석을 하려 합니다. 집계(`GROUP BY`) 없이 원본 행을 유지하며 최솟값을 붙이세요.",
    "schema": "orders(user_id INT, order_date DATE, amount INT)",
    "sample_rows": [
      "U1 | 2023-02-01 | Cohort: 2023-01-01",
      "U1 | 2023-01-01 | Cohort: 2023-01-01"
    ],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "파티션 내의 최솟값을 구하는 `MIN(col) OVER (PARTITION BY ...)`를 사용하면 모든 행에 동일한 '첫 구매일' 값이 복제됩니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_zscore_outlier_detection",
    "title": "이상치 탐지: Z-Score 계산",
    "body": "매출 데이터에서 평균으로부터 표준편차의 3배 이상 떨어진 이상치를 찾기 위해 Z-Score `(Value - Avg) / StdDev`를 계산하려 합니다. 윈도우 함수로 평균과 표준편차를 한 번에 구해서 식을 만드세요.",
    "schema": "sales(shop_id INT, revenue INT)",
    "sample_rows": [],
    "difficulty": "Lv4 고급",
    "kind": "SQL",
    "hint": "`OVER()`를 비워두면 전체 데이터셋에 대한 평균과 표준편차를 계산합니다. 이를 각 행의 값과 연산합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_window_frame_centered_avg",
    "title": "중심 이동 평균: 어제+오늘+내일",
    "body": "데이터 분석 시 시계열을 부드럽게 만들기 위해 '나를 중심으로 앞뒤 1일'의 평균을 구하고 싶습니다. 3일 이동평균이지만 프레임이 대칭입니다.",
    "schema": "daily_temp(dt DATE, temp DECIMAL)",
    "sample_rows": [],
    "difficulty": "Lv4 고급",
    "kind": "SQL",
    "hint": "`ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING`을 쓰면 (전 행, 현 행, 다음 행) 총 3개의 평균을 구합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_ytd_partition_year",
    "title": "YTD (Year-To-Date) 매출 집계",
    "body": "일별 매출을 누적하되, 연도가 바뀌면 누적 합계가 0부터 다시 시작되게 하고 싶습니다. `PARTITION BY`에 어떤 값을 넣어야 할까요?",
    "schema": "sales(dt DATE, amount INT)",
    "sample_rows": [
      "2023-12-31 | 누적 1000",
      "2024-01-01 | 누적 10 (리셋됨)"
    ],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "연도별로 그룹을 나누면(`PARTITION BY YEAR(dt)`) 해가 바뀔 때마다 윈도우가 새로 시작됩니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_consecutive_days_grouping",
    "title": "연속 기록 찾기: Gaps-and-Islands 기초",
    "body": "매일 로그인한 유저의 연속 출석 일수를 구하기 위한 첫 단계입니다. '로그인 날짜'에서 '순위(Row Number)'만큼의 일수를 뺐을 때, 연속된 날짜들은 **같은 값**을 가지게 됩니다. 이 로직을 작성하세요.",
    "schema": "attendance(user_id INT, login_dt DATE)",
    "sample_rows": [
      "1일(rk1) -> 0",
      "2일(rk2) -> 0 (그룹A)",
      "5일(rk3) -> 2 (그룹B)"
    ],
    "difficulty": "Lv5 심화",
    "kind": "SQL",
    "hint": "날짜가 하루씩 증가하고 순위도 1씩 증가하므로, 둘의 차이는 연속된 기간 동안 일정하게 유지됩니다. 이 차이값이 그룹 ID가 됩니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_funnel_lead_check",
    "title": "퍼널 분석: 다음 단계로 전환되었는가?",
    "body": "페이지 뷰(View) 로그 옆에, 해당 유저가 바로 다음에 '장바구니(Cart)' 행동을 했는지 여부를 O/X로 표시하고 싶습니다. `LEAD` 함수를 응용하세요.",
    "schema": "actions(user_id INT, action_name TEXT, ts TIMESTAMP)",
    "sample_rows": [
      "View | Next: Cart -> O",
      "Cart | Next: Purchase -> X"
    ],
    "difficulty": "Lv3 중급",
    "kind": "SQL",
    "hint": "`LEAD(action_name) OVER (PARTITION BY user ORDER BY ts) = 'Cart'` 조건식을 사용합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_pivot_sum_case",
    "title": "피벗 테이블: 행을 열로 변환 (Pivot)",
    "body": "세로로 긴 월별 매출 데이터를 가로로 펼쳐서 [Jan_Sales, Feb_Sales] 컬럼으로 만들고 싶습니다. `SUM` 함수 안에 `CASE WHEN`을 넣는 패턴을 사용하세요.",
    "schema": "monthly_sales(month INT, amount INT)",
    "sample_rows": [],
    "difficulty": "Lv3 중급",
    "kind": "SQL",
    "hint": "각 월에 해당하는 값만 남기고 나머지는 0으로 만든 뒤 합계(`SUM`)를 구하면 특정 월의 매출만 컬럼으로 추출됩니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_string_agg_group_concat",
    "title": "문자열 합치기: 주문 상품 목록 만들기",
    "body": "하나의 주문번호(order_id)에 여러 상품이 있습니다. 주문번호별로 상품명들을 쉼표(`,`)로 연결해 한 줄로 보고 싶습니다. (DB에 따라 `STRING_AGG`, `GROUP_CONCAT` 등을 사용)",
    "schema": "order_items(order_id INT, product_name TEXT)",
    "sample_rows": [
      "100 | Apple, Banana, Cherry"
    ],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "MySQL은 `GROUP_CONCAT(product_name SEPARATOR ', ')`, PostgreSQL/SQLServer는 `STRING_AGG`를 사용합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_reverse_running_total_budget",
    "title": "잔여 예산 계산 (Reverse Running Total)",
    "body": "프로젝트의 총 예산이 주어졌을 때, 지출 내역을 시간순으로 조회하며 '남은 예산'을 표시하고 싶습니다. `전체예산 - 누적지출` 형식을 사용하세요.",
    "schema": "expenses(cost INT, used_at DATE)",
    "sample_rows": [
      "Cost 100 | Remain 900",
      "Cost 200 | Remain 700"
    ],
    "difficulty": "Lv3 중급",
    "kind": "SQL",
    "hint": "상수(총 예산)에서 `SUM(cost) OVER (ORDER BY ...)`인 누적 합계를 빼주면 됩니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_weighted_moving_avg",
    "title": "가중 이동 평균 (Weighted Moving Avg)",
    "body": "최근 데이터에 더 가중치를 두고 싶습니다. `오늘*0.5 + 어제*0.3 + 그제*0.2`로 평균을 구하는 식을 `LAG`를 이용해 작성하세요.",
    "schema": "stock(dt DATE, price DECIMAL)",
    "sample_rows": [],
    "difficulty": "Lv3 중급",
    "kind": "SQL",
    "hint": "`LAG` 함수를 여러 번 호출하여 각각 다른 가중치를 곱해서 더합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_boolean_aggregation_max",
    "title": "조건 충족 여부 확인: 하나라도 있으면 1",
    "body": "유저가 가입 후 한 번이라도 '반품(Return)'을 한 적이 있는지 `is_returned` (1/0)로 표시하고 싶습니다. `MAX`와 `CASE WHEN`을 조합하여 유저별로 집계하세요.",
    "schema": "orders(user_id INT, status TEXT)",
    "sample_rows": [
      "U1 | Order, Return, Order -> 1",
      "U2 | Order, Order -> 0"
    ],
    "difficulty": "Lv3 중급",
    "kind": "SQL",
    "hint": "하나라도 1(True)이 있으면 `MAX` 값은 1이 됩니다. Boolean OR 연산의 집계 버전으로 자주 쓰이는 테크닉입니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_cume_dist_percentile",
    "title": "누적 분포: 상위 몇 %인가?",
    "body": "내 점수가 전체 수강생 중 상위 몇 % 위치에 있는지(예: 0.1이면 상위 10%) 알고 싶습니다. `CUME_DIST()` 함수를 사용해보세요.",
    "schema": "scores(student_id INT, score INT)",
    "sample_rows": [],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "`CUME_DIST()`는 Cumulative Distribution(누적 분포) 값을 반환합니다. 점수 내림차순 정렬 시 앞쪽에 있을수록 값이 작습니다(혹은 오름차순 시 하위 % 계산).",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_last_value_ignore_nulls",
    "title": "결측치 채우기: 앞의 값으로 채우기 (Forward Fill)",
    "body": "데이터가 비어있을 때(NULL), 바로 앞의 유효한 값을 가져와서 채우고 싶습니다. `LAST_VALUE` 함수와 `IGNORE NULLS` 옵션을 사용해야 합니다. (지원 DB 확인 필요)",
    "schema": "sensor(ts TIMESTAMP, val INT)",
    "sample_rows": [
      "10 -> 10",
      "NULL -> 10 (Copy)",
      "20 -> 20"
    ],
    "difficulty": "Lv5 심화",
    "kind": "SQL",
    "hint": "`LAST_VALUE(val IGNORE NULLS) OVER (ORDER BY ts ROWS UNBOUNDED PRECEDING)` 형태로 씁니다. 현재까지의 값 중 NULL이 아닌 마지막 값을 가져옵니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_avg_partition_vs_global",
    "title": "비교 분석: 내 연봉 vs 부서 평균 vs 전체 평균",
    "body": "내 연봉 옆에 '부서 평균'과 '회사 전체 평균'을 나란히 출력하여 비교하고 싶습니다. 윈도우 함수의 `PARTITION BY` 유무를 활용해 두 개의 컬럼을 만드세요.",
    "schema": "emp(salary INT, dept TEXT)",
    "sample_rows": [],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "하나는 `PARTITION BY dept`를 쓰고, 다른 하나는 `OVER ()`로 비워두면 전체 평균이 됩니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_time_bucket_grouping",
    "title": "시간대 분석: 10분 단위로 그룹핑",
    "body": "로그 데이터를 10분 단위로 묶어서 건수를 세고 싶습니다. 분(minute) 정보를 10으로 나누고 내림(`FLOOR`)하여 그룹핑 키를 만드세요.",
    "schema": "logs(ts TIMESTAMP)",
    "sample_rows": [
      "10:05 -> 10:00",
      "10:18 -> 10:10"
    ],
    "difficulty": "Lv3 중급",
    "kind": "SQL",
    "hint": "`FLOOR(분 / 10) * 10`을 하면 0~9분은 0, 10~19분은 10... 처럼 변환되어 `GROUP BY` 하기 좋아집니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_lead_coalesce_default_date",
    "title": "날짜 구간 만들기: 종료일 추론",
    "body": "이력 데이터(`history`)에 시작일(`start_dt`)만 있습니다. 다음 이력의 시작일을 나의 종료일(`end_dt`)로 쓰되, 다음 이력이 없으면 '9999-12-31'로 채우세요.",
    "schema": "history(id INT, start_dt DATE)",
    "sample_rows": [],
    "difficulty": "Lv3 중급",
    "kind": "SQL",
    "hint": "`COALESCE(LEAD(start_dt) OVER (...), '9999-12-31')` 형식을 쓰면 마지막 행의 NULL 문제를 해결할 수 있습니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_percent_rank_relative_standing",
    "title": "상대적 순위: 하위 10% 찾기",
    "body": "성적이 낮은 순서대로 정렬했을 때 하위 10%에 해당하는 학생을 찾으려 합니다. `PERCENT_RANK()` 값이 0.1 이하인 경우를 찾으면 될까요?",
    "schema": "scores(score INT)",
    "sample_rows": [],
    "difficulty": "Lv3 중급",
    "kind": "SQL",
    "hint": "`PERCENT_RANK`는 0~1 사이 값을 반환합니다. 오름차순 정렬(ASC) 시 0에 가까울수록 낮은 점수(하위권)입니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_sum_case_conditional_running",
    "title": "조건부 누적 합계: 환불 제외 매출 누적",
    "body": "일별 매출을 누적하되, 상태가 'Refund'인 건은 제외하고(더하지 않고) 합계를 구하고 싶습니다. `SUM` 안에 `CASE`문을 넣어 윈도우 함수를 작성하세요.",
    "schema": "sales(dt DATE, amount INT, status TEXT)",
    "sample_rows": [
      "Paid 100 -> 누적 100",
      "Refund 50 -> 누적 100 (변동없음)",
      "Paid 50 -> 누적 150"
    ],
    "difficulty": "Lv3 중급",
    "kind": "SQL",
    "hint": "누적할 대상(`amount`)을 `CASE`문으로 걸러냅니다. 환불이면 0을 더하게 하여 누적값에 영향을 주지 않게 합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_lag_yoy_growth",
    "title": "YoY(전년 대비 증감률) 계산",
    "body": "월별 매출 테이블에서 '작년 동월'의 매출과 비교하여 성장률을 계산하려 합니다. 데이터가 월별로 빠짐없이 있다고 가정할 때, `LAG`의 offset(간격) 파라미터를 어떻게 설정해야 할까요?",
    "schema": "monthly_sales(ym DATE, amount DECIMAL)",
    "sample_rows": [
      "2023-01 | 100",
      "...",
      "2024-01 | 120 (비교대상: 100)"
    ],
    "difficulty": "Lv3 중급",
    "kind": "SQL",
    "hint": "월별 데이터라면 1년 전은 12칸 뒤에 있습니다. `LAG(amount, 12) OVER (ORDER BY ym)`을 사용하세요.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_window_frame_7day_avg",
    "title": "이동 평균: 최근 7일 평균 (Rolling Average)",
    "body": "주간 트렌드를 보기 위해 '오늘을 포함한 최근 7일간'의 방문자 수 평균을 구하고 싶습니다. `AVG`와 `ROWS BETWEEN`을 사용하여 윈도우 프레임을 설정하세요.",
    "schema": "visitors(dt DATE, cnt INT)",
    "sample_rows": [],
    "difficulty": "Lv4 고급",
    "kind": "SQL",
    "hint": "오늘 포함 7일이려면, 내 앞의 6일(`6 PRECEDING`)과 나(`CURRENT ROW`)를 합쳐야 합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_coalesce_divide_zero",
    "title": "안전한 나눗셈: 0으로 나누기 방지",
    "body": "클릭률(CTR)을 구하기 위해 `clicks / impressions`를 계산하려는데, 노출(impressions)이 0인 경우가 있어 에러가 발생합니다. `NULLIF`를 쓰거나 `COALESCE`를 쓸 수 있지만, 여기선 분모가 0이면 NULL을 반환하게 하는 표준 패턴을 생각해보세요.",
    "schema": "ads(clicks INT, impressions INT)",
    "sample_rows": [
      "10 / 0 -> NULL (Error X)"
    ],
    "difficulty": "Lv3 중급",
    "kind": "SQL",
    "hint": "`clicks / NULLIF(impressions, 0)`을 쓰면 분모가 0일 때 NULL이 되어 전체 결과가 NULL(에러 없음)이 됩니다. 이후 필요하면 `COALESCE`로 0 처리합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_max_over_high_water_mark",
    "title": "Running Max: 지금까지의 최고 기록",
    "body": "게임 점수 로그를 시간순으로 보면서, '해당 시점까지의 역대 최고 점수(High Water Mark)'를 매 행마다 표시하고 싶습니다.",
    "schema": "scores(user_id INT, created_at TIMESTAMP, score INT)",
    "sample_rows": [
      "10점 -> Max 10",
      "5점 -> Max 10",
      "20점 -> Max 20"
    ],
    "difficulty": "Lv3 중급",
    "kind": "SQL",
    "hint": "기본 윈도우(`RANGE UNBOUNDED PRECEDING`)를 사용하는 `MAX` 함수는 정렬 순서에 따라 누적 최대값을 보여줍니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_datediff_months_service",
    "title": "근속 개월 수 계산",
    "body": "입사일(joined_at)과 기준일(target_dt) 사이의 차이를 '개월 수'로 구하고 싶습니다. 단순 일수 나누기 30은 부정확하므로, SQL의 월 단위 차이 함수(혹은 로직)를 사용하세요.",
    "schema": "employees(joined_at DATE, target_dt DATE)",
    "sample_rows": [],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "MySQL/MariaDB 등에서는 `TIMESTAMPDIFF(MONTH, joined_at, target_dt)`를, SQL Server는 `DATEDIFF(MONTH, ...)`를 씁니다. 문맥에 맞는 월 차이 함수를 선택하세요.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_first_value_attribution",
    "title": "첫 유입 채널 찾기: Attribution 분석",
    "body": "유저가 여러 번 방문했지만, 최초로 방문했을 때의 유입 경로(channel)를 모든 로그에 표시하여 '이 유저는 원래 어디서 왔나'를 분석하고 싶습니다. `FIRST_VALUE`를 사용하세요.",
    "schema": "visits(user_id INT, visited_at TIMESTAMP, channel TEXT)",
    "sample_rows": [
      "Google (10:00)",
      "Direct (12:00) -> Original: Google"
    ],
    "difficulty": "Lv3 중급",
    "kind": "SQL",
    "hint": "`PARTITION BY`로 유저를 묶고 시간순 정렬한 뒤 맨 첫 값을 가져오면 됩니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_lag_date_gap",
    "title": "데이터 누락 탐지: 날짜가 끊긴 곳 찾기",
    "body": "일별 로그가 연속되어야 하는데 중간에 빠진 날짜가 있는지 확인하려 합니다. `LAG`로 이전 날짜를 가져온 뒤, 현재 날짜와의 차이가 1보다 큰 경우를 찾으세요.",
    "schema": "logs(log_date DATE)",
    "sample_rows": [
      "1일, 2일, 4일 -> 4일에서 Gap 감지"
    ],
    "difficulty": "Lv3 중급",
    "kind": "SQL",
    "hint": "`DATEDIFF(log_date, LAG(log_date) OVER(...)) > 1` 이면 중간에 하루 이상 비었다는 뜻입니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_ntile_decile_analysis",
    "title": "고객 등급 나누기: 10분위(Decile) 분석",
    "body": "구매 금액(amount) 기준으로 고객들을 1등급부터 10등급까지 나누어 마케팅에 활용하려 합니다. 금액이 많은 순서대로 1등급을 부여하세요.",
    "schema": "customers(id INT, amount DECIMAL)",
    "sample_rows": [],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "`NTILE(10) OVER (ORDER BY amount DESC)`를 쓰면 상위 10%가 1그룹, 그 다음 10%가 2그룹... 순으로 배정됩니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_dense_rank_price_tier",
    "title": "가격대별 순위: 동일 가격은 같은 등수로",
    "body": "상품 가격이 비싼 순서대로 순위를 매기되, 가격이 같으면 같은 순위를 주고 그 다음 순위도 연속되게(1, 1, 2, 3...) 하고 싶습니다.",
    "schema": "products(name TEXT, price INT)",
    "sample_rows": [
      "A: 1000 (1등)",
      "B: 1000 (1등)",
      "C: 900 (2등)"
    ],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "순위가 건너뛰지 않길 원할 때는 무조건 `DENSE_RANK`입니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_coalesce_search_params",
    "title": "동적 검색 조건: 파라미터가 없으면 전체 조회",
    "body": "검색어(`@query`)가 들어오면 해당 이름만 찾고, 검색어가 NULL이면 전체 목록을 출력하는 트릭을 `COALESCE`를 활용해 WHERE 절에 작성해보세요.",
    "schema": "users(name TEXT)",
    "sample_rows": [],
    "difficulty": "Lv4 고급",
    "kind": "SQL",
    "hint": "`name = COALESCE(@query, name)`: 쿼리가 있으면 name=@query가 되고, 없으면 name=name(항상 참)이 되어 전체가 조회됩니다. (성능 주의)",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_datediff_seconds_latency",
    "title": "처리 시간(Latency) 분석: 초 단위 차이",
    "body": "요청 시간(req_at)과 응답 시간(res_at)의 차이를 '초(Second)' 단위로 계산하여 평균 응답 속도를 구하려 합니다.",
    "schema": "api_logs(req_at TIMESTAMP, res_at TIMESTAMP)",
    "sample_rows": [],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "MySQL은 `TIMESTAMPDIFF(SECOND, req_at, res_at)`, SQL Server는 `DATEDIFF(SECOND, req_at, res_at)`를 사용합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_min_over_salary_range",
    "title": "연봉 범위 확인: 최저 연봉과의 차이",
    "body": "각 직원의 연봉이 해당 직무(job)의 '최저 연봉'보다 얼마나 더 많은지 계산하고 싶습니다. `GROUP BY` 없이 윈도우 함수로 최저 연봉을 구해서 빼세요.",
    "schema": "emp(job TEXT, salary INT)",
    "sample_rows": [
      "Dev | 5000 | (Min: 3000) -> +2000"
    ],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "각 행마다 `MIN(salary) OVER (PARTITION BY job)` 값을 생성하여 본인 연봉에서 뺍니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_lead_churn_signal",
    "title": "이탈 신호 감지: 다음 접속이 없을 때",
    "body": "유저의 접속 로그에서, '다음 접속일'이 존재하지 않는(NULL) 경우를 '마지막 접속(Last Login)'으로 판단하여 표시하려 합니다.",
    "schema": "logins(user_id INT, login_dt DATE)",
    "sample_rows": [],
    "difficulty": "Lv3 중급",
    "kind": "SQL",
    "hint": "`LEAD(...)`의 결과가 `IS NULL`이면 그 행이 해당 파티션(유저)의 마지막 데이터라는 뜻입니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_count_over_partition_size",
    "title": "그룹 크기 확인: 우리 팀은 몇 명?",
    "body": "직원 목록을 출력하면서, 옆에 '소속 부서의 총 인원 수'를 함께 표시하고 싶습니다. 집계 쿼리를 조인하지 말고 윈도우 함수로 해결하세요.",
    "schema": "emp(name TEXT, dept TEXT)",
    "sample_rows": [
      "A | HR | 2명",
      "B | HR | 2명",
      "C | IT | 1명"
    ],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "`COUNT(*) OVER (PARTITION BY dept)`를 쓰면 각 행마다 해당 부서의 전체 인원수가 계산되어 붙습니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_lag_default_param",
    "title": "LAG 기본값: 첫 구매라 이전 기록이 없다면?",
    "body": "이번 구매 금액과 이전 구매 금액의 차이를 구하는데, '첫 구매'라 이전 금액이 NULL인 경우 차이를 0으로 간주하고 싶습니다. `LAG`의 3번째 인자(default)를 활용하세요.",
    "schema": "orders(user_id INT, amount INT)",
    "sample_rows": [],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "`LAG(amount, 1, amount)`라고 쓰면 이전 값이 없을 때 '내 금액(amount)'을 가져오므로, `amount - LAG` 결과가 0이 됩니다. (혹은 0을 기본값으로 쓰고 로직을 바꿀 수도 있음)",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_sum_over_cumulative_percent",
    "title": "파레토 법칙: 누적 매출 비중 구하기",
    "body": "매출이 높은 상품부터 정렬했을 때, 상위 상품들의 매출 합계가 전체 매출의 몇 %를 차지하는지(누적 비율) 알고 싶습니다. `SUM() OVER(ORDER BY..)`와 `SUM() OVER()`를 나누세요.",
    "schema": "sales(product TEXT, amount INT)",
    "sample_rows": [
      "1등: 50 -> 누적 50 (50%)",
      "2등: 30 -> 누적 80 (80%)",
      "3등: 20 -> 누적 100 (100%)"
    ],
    "difficulty": "Lv4 고급",
    "kind": "SQL",
    "hint": "분자: `SUM(amount) OVER (ORDER BY amount DESC)` (누적합)\n분모: `SUM(amount) OVER ()` (전체합)",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_row_number_delete_dups",
    "title": "중복 제거 로직: DELETE 문과 결합 (개념)",
    "body": "중복된 데이터 중 id가 가장 큰 최신 데이터 하나만 남기고 나머지를 삭제(`DELETE`)하려 합니다. 보통 `ROW_NUMBER`로 순위를 매긴 CTE를 만들고, `DELETE FROM CTE WHERE ...` 구문을 씁니다. 이때 남길 행의 조건은?",
    "schema": "logs(id INT, msg TEXT)",
    "sample_rows": [],
    "difficulty": "Lv3 중급",
    "kind": "SQL",
    "hint": "최신 데이터를 1등으로 만들었다면, `rn > 1`인 행들(2등, 3등...)이 삭제 대상이 됩니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_avg_over_deviation",
    "title": "편차 구하기: 평균보다 얼마나 다른가?",
    "body": "일별 기온 데이터에서 '월 평균 기온'과 '그 날의 기온' 차이(편차)를 구하세요.",
    "schema": "weather(dt DATE, temp DECIMAL)",
    "sample_rows": [],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "`PARTITION BY`에 월(Month) 정보를 넣어 월별 평균을 구하고, 현재 행의 `temp`에서 뺍니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_lead_boolean_check",
    "title": "패턴 매칭: 성공 후 바로 실패한 경우 찾기",
    "body": "작업 로그에서 상태가 'Success'인 바로 다음 작업이 'Fail'인 경우를 찾고 싶습니다. `LEAD`로 다음 상태를 가져와서 비교하세요.",
    "schema": "jobs(id INT, status TEXT, created_at TIMESTAMP)",
    "sample_rows": [],
    "difficulty": "Lv3 중급",
    "kind": "SQL",
    "hint": "현재 행이 Success이고 `LEAD(...)`가 Fail인 행을 필터링하면 됩니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_rank_dense_rank_concept",
    "title": "개념 확인: RANK와 DENSE_RANK의 차이",
    "body": "1등이 3명일 때, 그 다음 사람의 등수가 `4등`이 되는 함수와 `2등`이 되는 함수를 순서대로 나열하세요.",
    "schema": "N/A (개념 문제)",
    "sample_rows": [],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "`RANK`는 1, 1, 1 다음 4 (건너뜀), `DENSE_RANK`는 1, 1, 1 다음 2 (빽빽함)입니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_ntile_quartile",
    "title": "데이터 4등분하기: NTILE",
    "body": "전체 학생을 성적(score) 순으로 줄 세운 뒤, 정확히 4개의 그룹(1분위~4분위)으로 나누고 싶습니다. 1등 그룹에게는 1, 꼴찌 그룹에게는 4가 부여되도록 하세요.",
    "schema": "students(name TEXT, score INT)",
    "sample_rows": [
      "A | 100 -> 1",
      "B | 90 -> 1",
      "C | 80 -> 2"
    ],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "`NTILE(n)` 함수는 데이터를 n개의 바구니에 똑같이 나누어 담습니다. `NTILE(4) OVER (ORDER BY score DESC)`를 사용하세요.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_coalesce_math",
    "title": "NULL이 포함된 연산: 급여 + 보너스",
    "body": "총 수령액을 계산하기 위해 `salary + bonus`를 하려고 합니다. 하지만 보너스를 받지 못한 직원의 bonus 컬럼이 NULL이라서, 더하기 결과가 NULL이 됩니다. 보너스가 없으면 0으로 처리하여 더하세요.",
    "schema": "employees(salary INT, bonus INT)",
    "sample_rows": [
      "3000 | NULL -> 3000",
      "4000 | 500 -> 4500"
    ],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "SQL에서 `숫자 + NULL`은 `NULL`입니다. 반드시 `COALESCE(bonus, 0)`으로 NULL을 0으로 바꿔준 뒤 더해야 합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_lead_default_value",
    "title": "LEAD 기본값 설정: 다음 단계가 없으면?",
    "body": "주문의 처리 단계(status) 흐름을 보고 있는데, 마지막 단계인 경우 '다음 단계'가 없어 NULL이 나옵니다. 이 경우 NULL 대신 'Completed'라고 표시하고 싶습니다. `LEAD` 함수의 3번째 인자를 활용하세요.",
    "schema": "process(step_id INT, status TEXT)",
    "sample_rows": [
      "1 | Order -> Pay",
      "2 | Pay -> Ship",
      "3 | Ship -> Completed"
    ],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "`LEAD(col, offset, default_value)` 형식을 사용합니다. 예: `LEAD(status, 1, 'Completed')`",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_lag_offset_wow",
    "title": "지난주 대비 비교: LAG의 Offset 활용",
    "body": "매일 기록되는 데이터에서 '어제'가 아니라 '7일 전(지난주 같은 요일)'의 매출과 비교하고 싶습니다. `LAG` 함수의 2번째 인자(offset)를 사용하세요.",
    "schema": "daily_sales(dt DATE, amount INT)",
    "sample_rows": [
      "2023-01-08 (일) -> 비교대상: 2023-01-01 (일)"
    ],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "`LAG(amount, 7) OVER (ORDER BY dt)`를 쓰면 7행 앞의 데이터를 가져옵니다. (데이터가 매일 빠짐없이 있다는 가정 하에)",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_avg_partition_diff",
    "title": "평균과의 차이: 내 점수는 평균보다 얼마나 높을까?",
    "body": "학생 본인의 점수와 '해당 반(class)의 평균 점수'의 차이를 구하고 싶습니다. `GROUP BY`를 쓰지 않고 윈도우 함수 `AVG`를 사용하여 각 행에 평균값을 붙인 뒤 빼세요.",
    "schema": "scores(name TEXT, class TEXT, score INT)",
    "sample_rows": [
      "A | Math | 90 (반평균 80) -> +10"
    ],
    "difficulty": "Lv3 중급",
    "kind": "SQL",
    "hint": "`AVG(score) OVER (PARTITION BY class)`를 하면 해당 행 옆에 반 평균이 붙습니다. 여기서 내 점수를 빼면 됩니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_row_number_pagination",
    "title": "게시판 페이징: 11~20번째 글 가져오기",
    "body": "게시글 목록에서 2페이지(11등부터 20등까지)에 해당하는 글만 가져오려고 합니다. `ROW_NUMBER`로 순번을 매긴 후, 서브쿼리 밖에서 범위를 지정하세요.",
    "schema": "posts(id INT, created_at TIMESTAMP)",
    "sample_rows": [],
    "difficulty": "Lv3 중급",
    "kind": "SQL",
    "hint": "내부에서 `ROW_NUMBER() OVER (ORDER BY created_at DESC) as rn`을 만들고, 외부 WHERE 절에서 `rn BETWEEN 11 AND 20`을 씁니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_min_over_lowest_price",
    "title": "카테고리 최저가 확인: 최저가와 비교",
    "body": "상품 목록을 출력하되, 해당 상품이 속한 카테고리의 '최저가'도 함께 컬럼으로 보여주고 싶습니다. (그래서 내 가격이 최저가인지 한눈에 보게요)",
    "schema": "products(name TEXT, category TEXT, price INT)",
    "sample_rows": [
      "TV | Electronics | 1000 | (Min: 500)",
      "Radio | Electronics | 500 | (Min: 500)"
    ],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "`MIN(price) OVER (PARTITION BY category)`를 사용하면 집계(Group by)로 행이 줄어들지 않고 원본 행 옆에 최저가가 붙습니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_datediff_age_calc",
    "title": "나이 계산 (연도 차이)",
    "body": "직원의 생년월일(birth_date)을 기준으로 현재(2025-01-01 기준이라고 가정) 몇 년을 살았는지, 즉 '한국식 나이 말고 만 나이와 유사한 연차'를 `DATEDIFF`나 연도 계산으로 구해보세요.",
    "schema": "employees(name TEXT, birth_date DATE)",
    "sample_rows": [],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "단순 연도 차이는 `YEAR(Current) - YEAR(Birth)`로 구하거나, DB에 따라 `DATEDIFF(year, birth, current)`를 쓸 수 있습니다. (일수 차이 / 365는 윤년 때문에 부정확할 수 있음)",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_last_value_frame_trap",
    "title": "함정 문제: LAST_VALUE가 이상해요",
    "body": "부서별로 가장 연봉이 높은 사람을 구하려고 `LAST_VALUE(name) OVER (PARTITION BY dept ORDER BY salary)`를 썼더니, 1등 이름이 아니라 자기 자신의 이름이 나옵니다. 무엇을 추가해야 전체 범위를 볼까요?",
    "schema": "emp(name TEXT, dept TEXT, salary INT)",
    "sample_rows": [],
    "difficulty": "Lv4 고급",
    "kind": "SQL",
    "hint": "기본 윈도우 프레임은 '처음부터 **현재 행까지**'입니다. 그래서 마지막 값(`LAST_VALUE`)이 항상 '나(현재 행)'가 됩니다. `ROWS BETWEEN ... AND UNBOUNDED FOLLOWING`으로 뒷부분까지 열어줘야 합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_percent_rank_top_percent",
    "title": "상위 N% 추출: PERCENT_RANK",
    "body": "게임 점수가 상위 1%에 드는 유저만 추출하고 싶습니다. `PERCENT_RANK` 함수를 사용하여 0~1 사이의 백분위 순위를 구하고 조건을 거세요.",
    "schema": "users(id INT, score INT)",
    "sample_rows": [],
    "difficulty": "Lv3 중급",
    "kind": "SQL",
    "hint": "`PERCENT_RANK()`는 0(1등)에서 1(꼴등) 사이의 값을 반환합니다. 상위 1%는 값이 0.01 이하인 경우입니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_count_over_duplicates",
    "title": "중복 데이터 찾기: GROUP BY 없이",
    "body": "이메일(email)이 중복된 사용자를 찾고 싶은데, 중복된 사용자의 '모든 컬럼 정보'를 보고 싶습니다. `GROUP BY`를 하면 다른 컬럼을 보기 힘드니, 윈도우 함수로 '중복 횟수' 컬럼을 만들어 필터링하세요.",
    "schema": "users(id INT, name TEXT, email TEXT)",
    "sample_rows": [
      "1 | A | a@test.com | cnt: 2",
      "2 | B | a@test.com | cnt: 2"
    ],
    "difficulty": "Lv3 중급",
    "kind": "SQL",
    "hint": "`COUNT(*) OVER (PARTITION BY email)`을 계산해서 그 값이 1보다 큰 행만 서브쿼리로 추출합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_datediff_recent_filter",
    "title": "최근 30일 데이터 필터링",
    "body": "오늘 날짜(NOW() 혹은 CURRENT_DATE)를 기준으로, 최근 30일 이내에 가입한 유저만 조회하는 WHERE 절을 `DATEDIFF`를 사용하여 작성하세요.",
    "schema": "users(id INT, join_date DATE)",
    "sample_rows": [],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "`DATEDIFF(CURRENT_DATE, join_date) BETWEEN 0 AND 30` 처럼 작성하여 미래 날짜는 제외하고 과거 30일만 가져옵니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_rank_dense_gap_check",
    "title": "순위의 빈 공간 확인: RANK와 DENSE_RANK 차이",
    "body": "특정 컬럼 기준으로 `RANK()` 값과 `DENSE_RANK()` 값이 **다른** 행을 찾으면, 그 앞 순위에 동점자가 존재했다는 뜻입니다. 이를 이용해 동점자가 발생한 구간을 찾는 로직을 생각해보세요.",
    "schema": "scores(id INT, score INT)",
    "sample_rows": [],
    "difficulty": "Lv4 고급",
    "kind": "SQL",
    "hint": "동점자가 없으면 두 순위는 항상 같습니다. 차이가 0이 아니라면 그 앞에 공동 순위가 있었다는 증거입니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_sum_over_category_total",
    "title": "비중 계산: (내 매출 / 카테고리 총 매출)",
    "body": "각 상품의 매출이 해당 카테고리 전체 매출에서 차지하는 비율(%)을 구하세요. `SUM(revenue) OVER (...)`를 분모로 사용해야 합니다.",
    "schema": "sales(product TEXT, category TEXT, revenue DECIMAL)",
    "sample_rows": [
      "A | Elec | 100 / 500 = 0.2"
    ],
    "difficulty": "Lv3 중급",
    "kind": "SQL",
    "hint": "`revenue / SUM(revenue) OVER (PARTITION BY category)` 형태로 계산합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_datediff_business_days",
    "title": "주말 제외 로직 (힌트)",
    "body": "두 날짜 사이의 일수를 `DATEDIFF`로 구하면 주말도 포함됩니다. 만약 주말을 대략적으로 제외하고 싶다면, 전체 일수에서 어떤 연산(7로 나누기 등)을 응용해야 할까요? (정확한 공휴일 제외는 달력 테이블이 필요하지만, 단순 5/7 근사치 아이디어를 떠올려보세요)",
    "schema": "tasks(start_dt DATE, end_dt DATE)",
    "sample_rows": [],
    "difficulty": "Lv4 고급",
    "kind": "SQL",
    "hint": "단순 근사치로는 `DATEDIFF(...) * 5 / 7`을 쓰거나, 복잡하게는 `WEEKDAY()` 함수를 조합해야 합니다. 이 문제는 아이디어 차원에서 접근해보세요.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_coalesce_filter",
    "title": "NULL 포함 필터링: <> 'Done'",
    "body": "status가 'Done'이 **아닌** 작업을 모두 찾고 싶습니다. `WHERE status <> 'Done'`이라고 쓰면 NULL인 행이 누락됩니다. `COALESCE`를 사용해 NULL도 결과에 포함되게 만드세요.",
    "schema": "tasks(id INT, status TEXT)",
    "sample_rows": [
      "1 | Doing -> O",
      "2 | NULL -> O (포함되어야 함)",
      "3 | Done -> X"
    ],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "`COALESCE(status, '') <> 'Done'`으로 비교하면 NULL이 빈 문자열로 바뀌어 'Done'과 다르다고 판단되므로 결과에 나옵니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_lead_time_duration",
    "title": "종료 시간 추론: 다음 시작 시간이 내 종료 시간",
    "body": "로그에 시작 시간(start_at)만 있고 종료 시간이 없습니다. '다음 이벤트의 시작 시간'을 '내 이벤트의 종료 시간'으로 간주하여 `end_at` 컬럼을 만드세요.",
    "schema": "events(event_id INT, start_at TIMESTAMP)",
    "sample_rows": [],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "`LEAD(start_at) OVER (ORDER BY start_at)`을 하면 바로 다음 행의 시작 시간을 가져올 수 있습니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_row_number_median",
    "title": "중앙값(Median) 찾기 기초",
    "body": "데이터를 순서대로 나열했을 때 정확히 한가운데 있는 값을 찾으려면, 순번(`ROW_NUMBER`)과 전체 개수(`COUNT`)를 비교해야 합니다. 중앙값의 위치를 찾는 조건식은 무엇일까요? (홀수 개일 때)",
    "schema": "values(val INT)",
    "sample_rows": [],
    "difficulty": "Lv4 고급",
    "kind": "SQL",
    "hint": "전체 개수(cnt)가 5개면 3등이 중앙입니다. `rn = (cnt + 1) / 2` (혹은 짝수일 경우 평균 등 추가 로직 필요) 조건을 사용합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_dense_rank_third_distinct",
    "title": "3번째로 높은 '고유한' 점수 찾기",
    "body": "점수 분포가 `100, 100, 90, 90, 80` 일 때, 80점은 5등(RANK)이지만 고유한 값으로는 3번째(DENSE_RANK)입니다. 3번째로 높은 점수(80)를 가진 사람을 찾으세요.",
    "schema": "scores(name TEXT, score INT)",
    "sample_rows": [],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "`DENSE_RANK()`를 쓰고 `WHERE rank = 3`을 걸면 중복을 건너뛰지 않고 3번째 그룹을 찾습니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_lag_rolling_volatility",
    "title": "변동성 확인: 전일 대비 가격 변화량 절대값",
    "body": "주식 가격이 전일 대비 얼마나 변했는지(오르든 내리든) '변동폭'을 알고 싶습니다. `LAG`를 이용해 차이를 구하고, `ABS()` 함수로 절대값을 씌우세요.",
    "schema": "stock(date DATE, price DECIMAL)",
    "sample_rows": [
      "100 -> 90 : 변동폭 10"
    ],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "`ABS(price - LAG(price) OVER (...))` 를 사용하면 상승/하락 관계없이 변화의 크기만 구할 수 있습니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_coalesce_basic",
    "title": "NULL 채우기: COALESCE 기초",
    "body": "users 테이블에서 사용자의 별명(nickname)을 조회하려고 합니다. 만약 별명이 NULL이라면 실명(real_name)을, 실명도 NULL이라면 'Unknown'을 출력하는 SQL을 작성하세요.",
    "schema": "users(nickname TEXT, real_name TEXT)",
    "sample_rows": [
      "NULL | Jason",
      "Terminator | Arnold",
      "NULL | NULL"
    ],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "COALESCE(컬럼1, 컬럼2, '기본값') 순서로 나열하면, 앞에서부터 순서대로 NULL이 아닌 첫 번째 값을 반환합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_datediff_shipping",
    "title": "날짜 차이 계산: 배송 소요 시간",
    "body": "orders 테이블에서 주문일(order_date)과 배송 완료일(delivered_date)의 차이를 일(Day) 단위로 계산하여 'days_taken'이라는 컬럼으로 조회하세요.",
    "schema": "orders(order_id INT, order_date DATE, delivered_date DATE)",
    "sample_rows": [
      "1 | 2023-01-01 | 2023-01-05",
      "2 | 2023-01-10 | 2023-01-11"
    ],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "DB 종류에 따라 다르지만 보통 `DATEDIFF(종료일, 시작일)` 혹은 `DATEDIFF(단위, 시작일, 종료일)` 형식을 씁니다. 여기서는 `DATEDIFF(delivered_date, order_date)` 로직을 생각해보세요.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_window_basic_row_number",
    "title": "그룹별 순번 매기기: ROW_NUMBER 입문",
    "body": "employees 테이블에서 각 부서(department)별로 급여(salary)가 높은 순서대로 1부터 순번을 매겨보세요. 순번 컬럼명은 'salary_rank'로 지정하세요.",
    "schema": "employees(name TEXT, department TEXT, salary INT)",
    "sample_rows": [
      "Alice | IT | 5000",
      "Bob | IT | 4500",
      "Charlie | HR | 4000"
    ],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "`ROW_NUMBER() OVER (PARTITION BY 그룹기준컬럼 ORDER BY 정렬기준컬럼 DESC)` 구문을 사용합니다. 부서로 나누고(Partition), 급여로 정렬(Order)해야 합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_window_rank_vs_dense",
    "title": "공동 등수 처리: RANK vs DENSE_RANK",
    "body": "학생들의 성적(score)을 기준으로 등수를 매기려고 합니다. 점수가 같을 경우 공동 등수(예: 1등, 1등)를 부여하되, 그 다음 등수가 건너뛰지 않고 이어지게(예: 3등이 아닌 2등) 하려면 어떤 함수를 써야 할까요?",
    "schema": "students(name TEXT, score INT)",
    "sample_rows": [
      "A | 100",
      "B | 100",
      "C | 90"
    ],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "`RANK()`는 공동 1등이 2명이면 다음은 3등이 됩니다. 반면 `DENSE_RANK()`는 'Dense(빽빽한)'라는 뜻처럼 번호를 건너뛰지 않고 2등을 부여합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_window_lag_basic",
    "title": "이전 행 값 가져오기: LAG 기초",
    "body": "일별 매출(sales) 테이블에서, '어제 매출'을 'prev_sales'라는 컬럼으로 오늘 날짜 행에 함께 표시하고 싶습니다. 날짜(date)순으로 정렬된 상태에서 이전 행의 값을 가져오세요.",
    "schema": "daily_sales(date DATE, revenue INT)",
    "sample_rows": [
      "2023-01-01 | 100",
      "2023-01-02 | 150",
      "2023-01-03 | 120"
    ],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "`LAG(가져올컬럼) OVER (ORDER BY 정렬기준)`을 사용합니다. 파티션이 필요 없다면 ORDER BY만 적으면 됩니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_window_lead_basic",
    "title": "다음 행 값 가져오기: LEAD 기초",
    "body": "로그인 로그(logs) 테이블에서, 유저별로 '다음 번 접속일'이 언제였는지 확인하고 싶습니다. `next_login_date`라는 컬럼을 생성하세요.",
    "schema": "logs(user_id INT, login_date DATE)",
    "sample_rows": [
      "1 | 2023-01-01",
      "1 | 2023-01-05",
      "2 | 2023-01-02"
    ],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "LAG의 반대입니다. `LEAD` 함수를 사용하며, 유저별로 계산해야 하므로 `PARTITION BY user_id`가 필수입니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_row_number_deduplication",
    "title": "중복 제거: 가장 최신 기록만 남기기",
    "body": "시스템 오류로 동일한 주문(order_id)의 상태 변경 로그가 여러 번 쌓였습니다. 각 order_id별로 가장 최근(updated_at 기준)의 로그 하나만 필터링하는 쿼리의 핵심 로직을 작성하세요. (서브쿼리나 CTE는 생략하고 윈도우 함수 부분만 작성)",
    "schema": "order_logs(order_id INT, status TEXT, updated_at TIMESTAMP)",
    "sample_rows": [
      "100 | Shipped | 10:00",
      "100 | Delivered | 12:00"
    ],
    "difficulty": "Lv3 중급",
    "kind": "SQL",
    "hint": "최신순으로 번호를 매기려면 `ORDER BY updated_at DESC`를 씁니다. 이후 WHERE절에서 rn = 1 인 것만 추출하면 됩니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_lag_growth_rate",
    "title": "전일 대비 증감률(WoW/DoD) 계산",
    "body": "`LAG` 함수를 응용하여 전일 대비 매출 성장률((오늘매출 - 어제매출)/어제매출)을 계산하는 수식을 작성하세요.",
    "schema": "daily_sales(dt DATE, amount DECIMAL)",
    "sample_rows": [
      "2023-01-01 | 100",
      "2023-01-02 | 110"
    ],
    "difficulty": "Lv3 중급",
    "kind": "SQL",
    "hint": "먼저 `LAG`로 어제 매출을 구한 뒤, 이를 분모와 분자에 사용하여 나눗셈을 합니다. 0으로 나누기 오류 방지는 일단 고려하지 않아도 됩니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_coalesce_lag_fill",
    "title": "결측치 채우기: 직전 값으로 NULL 채우기",
    "body": "재고 데이터에 기록 누락이 있어 일부 날짜의 재고량(stock)이 NULL입니다. 이 경우 '직전 날짜의 재고량'을 가져와서 채우고 싶습니다. (단, 쿼리가 복잡해지므로 개념적으로 `LAG`와 `COALESCE`를 어떻게 조합할지 생각해보세요.)",
    "schema": "inventory(dt DATE, stock INT)",
    "sample_rows": [
      "01-01 | 100",
      "01-02 | NULL",
      "01-03 | 90"
    ],
    "difficulty": "Lv3 중급",
    "kind": "SQL",
    "hint": "`COALESCE(stock, LAG(stock) OVER (...))` 형태를 사용하면 현재 값이 NULL일 때 이전 값을 가져올 수 있습니다. (연속된 NULL 처리는 더 복잡한 테크닉이 필요합니다)",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_datediff_retention",
    "title": "리텐션 분석: N일 후 재방문 유저",
    "body": "유저가 가입일(join_date)로부터 정확히 7일 뒤에 접속(login_date)한 기록이 있는지 찾으려 합니다. WHERE 절에서 `DATEDIFF`를 활용해 조건을 작성하세요.",
    "schema": "activity(user_id INT, join_date DATE, login_date DATE)",
    "sample_rows": [
      "1 | 2023-01-01 | 2023-01-08"
    ],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "`DATEDIFF(login_date, join_date) = 7`을 조건으로 걸면 가입 후 7일차에 접속한 로그만 남길 수 있습니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_rank_top_n",
    "title": "Top N 추출: 부서별 연봉 Top 3",
    "body": "각 부서별로 연봉이 높은 상위 3명을 뽑고 싶습니다. 공동 등수가 있어도 3명까지만(혹은 3위까지만) 뽑으려면 WHERE 절에 어떤 조건을 써야 할까요? (서브쿼리에서 `RANK` 결과를 `rnk`로 만들었다고 가정)",
    "schema": "employees(dept TEXT, salary INT)",
    "sample_rows": [],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "윈도우 함수는 WHERE 절에 직접 쓸 수 없으므로 서브쿼리 사용 후 `WHERE rnk <= 3` 조건을 줍니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_sum_over_running_total",
    "title": "누적 합계(Running Total) 구하기",
    "body": "주문 일자별로 매출의 '누적 합계'를 구하고 싶습니다. `SUM()` 함수와 `OVER`를 조합하여 날짜가 흐름에 따라 매출이 쌓이는 값을 출력하세요.",
    "schema": "daily_sales(dt DATE, revenue INT)",
    "sample_rows": [
      "01-01 | 100 -> 100",
      "01-02 | 200 -> 300",
      "01-03 | 150 -> 450"
    ],
    "difficulty": "Lv3 중급",
    "kind": "SQL",
    "hint": "`SUM(col) OVER (ORDER BY col)`을 쓰면 정렬 순서에 따라 누적해서 더해나갑니다. `PARTITION BY`가 없으면 전체 데이터에 대해 누적합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_avg_over_moving_avg",
    "title": "이동 평균(Moving Average): 최근 3일 평균",
    "body": "주가 데이터에서 '최근 3일간의 종가 평균'을 구하려 합니다. `AVG()`와 `OVER`, 그리고 `ROWS BETWEEN` 구문을 활용해야 합니다.",
    "schema": "stock(dt DATE, close_price DECIMAL)",
    "sample_rows": [],
    "difficulty": "Lv4 고급",
    "kind": "SQL",
    "hint": "`ROWS BETWEEN 2 PRECEDING AND CURRENT ROW`는 '나를 포함해 앞의 2개 행' 즉 총 3개 행의 범위를 지정합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_lead_time_diff",
    "title": "세션 시간 계산: 다음 로그까지 걸린 시간",
    "body": "한 유저의 로그(timestamp) 사이의 시간 간격을 구하여, 해당 페이지에 얼마나 머물렀는지 추정하려 합니다. `LEAD` 함수를 이용해 '다음 로그 시간'을 가져와서 현재 로그 시간과의 차이를 구하세요.",
    "schema": "page_logs(user_id INT, page_id TEXT, visited_at TIMESTAMP)",
    "sample_rows": [
      "U1 | Home | 10:00:00",
      "U1 | Detail | 10:00:30"
    ],
    "difficulty": "Lv3 중급",
    "kind": "SQL",
    "hint": "현재 행에서 `LEAD`로 다음 행의 시간을 당겨온 뒤, 두 시간의 차이를 구하면 체류 시간이 됩니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_dense_rank_nth_highest",
    "title": "N번째로 높은 값 찾기: 연봉 2위 찾기",
    "body": "전체 사원 중 연봉이 '2번째'로 높은 금액을 받는 사원들을 모두 찾으세요. `LIMIT`을 쓰면 공동 2등을 다 못 가져오므로 `DENSE_RANK`를 써야 합니다.",
    "schema": "emp(name TEXT, salary INT)",
    "sample_rows": [],
    "difficulty": "Lv2 초급",
    "kind": "SQL",
    "hint": "연봉 내림차순으로 `DENSE_RANK`를 매기고, 외부 쿼리에서 `rank = 2`인 사람을 조회합니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_datediff_consecutive",
    "title": "연속 접속일 확인: 날짜 차이가 1일인가?",
    "body": "어제 접속하고 오늘 또 접속한 유저를 찾기 위해, `LAG`함수로 구한 '이전 접속일'과 '현재 접속일'의 차이가 1일인 경우를 찾으려 합니다. 조건식을 작성하세요.",
    "schema": "logins(user_id INT, login_dt DATE)",
    "sample_rows": [],
    "difficulty": "Lv3 중급",
    "kind": "SQL",
    "hint": "`DATEDIFF(current_dt, prev_dt) = 1`이면 연속 접속입니다. (주말 제외 등 복잡한 로직이 없다면)",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_over_count_total",
    "title": "전체 대비 비율: 비율 계산을 위한 전체 수",
    "body": "각 카테고리별 상품 수가 전체 상품 수에서 차지하는 비율을 구하고 싶습니다. `GROUP BY` 없이 원본 데이터를 유지하면서 '전체 행 개수'를 각 행에 붙이려면 `COUNT(*) OVER (...)`를 어떻게 써야 할까요?",
    "schema": "products(id INT, category TEXT)",
    "sample_rows": [
      "1 | A",
      "2 | A",
      "3 | B"
    ],
    "difficulty": "Lv3 중급",
    "kind": "SQL",
    "hint": "`OVER()` 안에 아무것도 넣지 않으면(빈 괄호), 전체 테이블을 하나의 윈도우로 보아 전체 개수를 모든 행에 붙여줍니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_coalesce_multi_columns",
    "title": "다중 연락처 우선순위: 집 > 휴대폰 > 회사",
    "body": "고객에게 연락을 하려 합니다. 집전화(home)가 있으면 그걸 쓰고, 없으면 휴대폰(mobile), 그것도 없으면 회사전화(office)를 쓰려 합니다. `COALESCE` 하나로 해결하세요.",
    "schema": "contacts(home TEXT, mobile TEXT, office TEXT)",
    "sample_rows": [
      "NULL | 010-... | 02-..."
    ],
    "difficulty": "Lv1 입문",
    "kind": "SQL",
    "hint": "인자를 여러 개 넣으면 됩니다. `COALESCE(home, mobile, office)`.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_first_value_vs_row_number",
    "title": "그룹별 첫 번째 값: FIRST_VALUE vs ROW_NUMBER",
    "body": "부서별로 가장 연봉이 높은 사람의 '이름'을 모든 행 옆에 붙여서 출력하고 싶습니다(집계가 아니라 윈도우 함수). `FIRST_VALUE`를 사용할 때 필수적인 절은 무엇인가요?",
    "schema": "emp(name TEXT, dept TEXT, salary INT)",
    "sample_rows": [],
    "difficulty": "Lv3 중급",
    "kind": "SQL",
    "hint": "`FIRST_VALUE(name) OVER (PARTITION BY dept ORDER BY salary DESC)`를 쓰면 해당 파티션 내 1등의 이름을 가져옵니다.",
    "problem_type": "코딩"
  },
  {
    "pid": "sql_lag_session_start",
    "title": "세션 정의: 30분 이상 공백이면 새 세션",
    "body": "로그 간 간격이 30분(`1800`초) 이상이면 새로운 세션으로 간주하여 'is_new_session' 플래그(1 또는 0)를 만들려고 합니다. `LAG`와 `DATEDIFF`(혹은 초 단위 차이 계산)를 활용한 CASE 문을 작성하세요.",
    "schema": "clicks(user_id INT, ts TIMESTAMP)",
    "sample_rows": [],
    "difficulty": "Lv4 고급",
    "kind": "SQL",
    "hint": "이전 시간(`LAG`)과의 차이가 1800초보다 크면 `1`, 아니면 `0`을 반환하는 식을 짭니다. 이는 세션 ID를 생성하는 기초 로직이 됩니다.",
    "problem_type": "코딩"
  }
]